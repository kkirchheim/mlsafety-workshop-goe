{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-GPU-bb1ccb6e-2bc9-c7a1-b25d-3eef9033e192/6/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This requires torchtext\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from pytorch_ood.dataset.txt import NewsGroup20, Reuters52, WMT16Sentences, Multi30k\n",
    "from pytorch_ood.model.gruclf import GRUClassifier\n",
    "from pytorch_ood.utils import ToUnknown, OODMetrics\n",
    "from pytorch_ood.detector import MaxSoftmax, EnergyBased\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "n_epochs = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# download datasets\n",
    "train_dataset = NewsGroup20(\"data/\", train=True, download=True)\n",
    "test_dataset = NewsGroup20(\"data/\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11293lines [00:00, 15811.16lines/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dataset)) # , max_tokens=10000# , specials=[\"<unk>\"]\n",
    "# vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch \n",
    "\n",
    "class MyDataset():\n",
    "    def __init__(self, n_dict=10000, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.n_dict = n_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 80000\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        length = 20 # torch.randint(low=1, high=50, size=(1,))\n",
    "        x = torch.randint(low=0, high=self.n_dict, size=(length,))\n",
    "        y = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prep(x):\n",
    "    return torch.tensor([vocab[v] for v in tokenizer(x)], dtype=torch.int64)\n",
    "\n",
    "train_in_dataset = NewsGroup20(\"data/\", train=True, transform=prep)\n",
    "test_dataset = NewsGroup20(\"data/\", train=False, transform=prep)\n",
    "\n",
    "train_out_dataset = MyDataset(target_transform=ToUnknown())  # transform=prep, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add padding, etc.\n",
    "def collate_batch(batch):\n",
    "    texts = [i[0] for i in batch]\n",
    "    labels = torch.tensor([i[1] for i in batch],  dtype=torch.int64)\n",
    "    t_lengths = torch.tensor([len(t) for t in texts])\n",
    "    max_t_length = torch.max(t_lengths)\n",
    "\n",
    "    padded = []\n",
    "    for text in texts:\n",
    "        t = torch.cat([torch.zeros(max_t_length-len(text), dtype=torch.long), text])\n",
    "        padded.append(t)\n",
    "    return torch.stack(padded,dim=0), labels\n",
    "\n",
    "train_loader = DataLoader(train_in_dataset + train_out_dataset, batch_size=32, shuffle=True, \n",
    "                          collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = GRUClassifier(num_classes=20, n_vocab=len(vocab))\n",
    "model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss: 0.16 Accuracy 0.00%\n",
      "Loss: 1.16 Accuracy 0.57%\n",
      "Loss: 1.49 Accuracy 0.89%\n",
      "Loss: 1.61 Accuracy 0.60%\n",
      "Loss: 1.68 Accuracy 0.61%\n",
      "Loss: 1.69 Accuracy 0.86%\n",
      "Loss: 1.71 Accuracy 0.92%\n",
      "Loss: 1.69 Accuracy 0.84%\n",
      "Loss: 1.69 Accuracy 0.93%\n",
      "Loss: 1.68 Accuracy 0.93%\n",
      "Loss: 1.69 Accuracy 0.93%\n",
      "Loss: 1.68 Accuracy 0.96%\n",
      "Loss: 1.69 Accuracy 0.98%\n",
      "Loss: 1.67 Accuracy 0.95%\n",
      "Loss: 1.65 Accuracy 0.93%\n",
      "Loss: 1.69 Accuracy 1.03%\n",
      "Loss: 1.70 Accuracy 0.99%\n",
      "Loss: 1.67 Accuracy 0.95%\n",
      "Loss: 1.65 Accuracy 0.92%\n",
      "Loss: 1.68 Accuracy 0.97%\n",
      "Loss: 1.67 Accuracy 1.03%\n",
      "Loss: 1.65 Accuracy 1.05%\n",
      "Loss: 1.65 Accuracy 1.06%\n",
      "Loss: 1.68 Accuracy 1.12%\n",
      "Loss: 1.70 Accuracy 1.15%\n",
      "Loss: 1.67 Accuracy 1.15%\n",
      "Loss: 1.68 Accuracy 1.13%\n",
      "Loss: 1.66 Accuracy 1.14%\n",
      "Loss: 1.68 Accuracy 1.15%\n",
      "Loss: 1.68 Accuracy 1.16%\n",
      "Loss: 1.67 Accuracy 1.16%\n",
      "Loss: 1.66 Accuracy 1.24%\n",
      "Loss: 1.67 Accuracy 1.26%\n",
      "Loss: 1.65 Accuracy 1.26%\n",
      "Loss: 1.69 Accuracy 1.26%\n",
      "Loss: 1.68 Accuracy 1.28%\n",
      "Loss: 1.68 Accuracy 1.26%\n",
      "Loss: 1.69 Accuracy 1.27%\n",
      "Loss: 1.69 Accuracy 1.26%\n",
      "Loss: 1.64 Accuracy 1.25%\n",
      "Loss: 1.67 Accuracy 1.25%\n",
      "Loss: 1.67 Accuracy 1.23%\n",
      "Loss: 1.66 Accuracy 1.21%\n",
      "Loss: 1.66 Accuracy 1.20%\n",
      "Loss: 1.66 Accuracy 1.21%\n",
      "Loss: 1.71 Accuracy 1.25%\n",
      "Loss: 1.73 Accuracy 1.26%\n",
      "Loss: 1.69 Accuracy 1.27%\n",
      "Loss: 1.72 Accuracy 1.27%\n",
      "Loss: 1.68 Accuracy 1.27%\n",
      "Loss: 1.65 Accuracy 1.28%\n",
      "Loss: 1.68 Accuracy 1.28%\n",
      "Loss: 1.70 Accuracy 1.31%\n",
      "Loss: 1.71 Accuracy 1.32%\n",
      "Loss: 1.69 Accuracy 1.33%\n",
      "Loss: 1.67 Accuracy 1.33%\n",
      "Loss: 1.67 Accuracy 1.34%\n",
      "Loss: 1.65 Accuracy 1.33%\n",
      "Loss: 1.69 Accuracy 1.35%\n",
      "Loss: 1.70 Accuracy 1.36%\n",
      "Loss: 1.69 Accuracy 1.38%\n",
      "Loss: 1.71 Accuracy 1.40%\n",
      "Loss: 1.66 Accuracy 1.39%\n",
      "Loss: 1.66 Accuracy 1.40%\n",
      "Loss: 1.67 Accuracy 1.40%\n",
      "Loss: 1.69 Accuracy 1.41%\n",
      "Loss: 1.67 Accuracy 1.41%\n",
      "Loss: 1.71 Accuracy 1.41%\n",
      "Loss: 1.67 Accuracy 1.43%\n",
      "Loss: 1.67 Accuracy 1.43%\n",
      "Loss: 1.62 Accuracy 1.43%\n",
      "Loss: 1.62 Accuracy 1.42%\n",
      "Loss: 1.64 Accuracy 1.43%\n",
      "Loss: 1.67 Accuracy 1.42%\n",
      "Loss: 1.66 Accuracy 1.44%\n",
      "Loss: 1.65 Accuracy 1.45%\n",
      "Loss: 1.67 Accuracy 1.46%\n",
      "Loss: 1.66 Accuracy 1.46%\n",
      "Loss: 1.67 Accuracy 1.46%\n",
      "Loss: 1.65 Accuracy 1.48%\n",
      "Loss: 1.64 Accuracy 1.48%\n",
      "Loss: 1.71 Accuracy 1.49%\n",
      "Loss: 1.68 Accuracy 1.48%\n",
      "Loss: 1.63 Accuracy 1.49%\n",
      "Loss: 1.65 Accuracy 1.49%\n",
      "Loss: 1.68 Accuracy 1.49%\n",
      "Loss: 1.67 Accuracy 1.51%\n",
      "Loss: 1.65 Accuracy 1.51%\n",
      "Loss: 1.71 Accuracy 1.53%\n",
      "Loss: 1.70 Accuracy 1.54%\n",
      "Loss: 1.68 Accuracy 1.54%\n",
      "Loss: 1.68 Accuracy 1.56%\n",
      "Loss: 1.67 Accuracy 1.56%\n",
      "Loss: 1.68 Accuracy 1.57%\n",
      "Loss: 1.68 Accuracy 1.57%\n",
      "Loss: 1.66 Accuracy 1.57%\n",
      "Loss: 1.69 Accuracy 1.58%\n",
      "Loss: 1.67 Accuracy 1.58%\n",
      "Loss: 1.72 Accuracy 1.60%\n",
      "Loss: 1.66 Accuracy 1.60%\n",
      "Loss: 1.67 Accuracy 1.60%\n",
      "Loss: 1.66 Accuracy 1.62%\n",
      "Loss: 1.69 Accuracy 1.61%\n",
      "Loss: 1.65 Accuracy 1.62%\n",
      "Loss: 1.69 Accuracy 1.62%\n",
      "Loss: 1.67 Accuracy 1.61%\n",
      "Loss: 1.67 Accuracy 1.61%\n",
      "Loss: 1.68 Accuracy 1.61%\n",
      "Loss: 1.65 Accuracy 1.62%\n",
      "Loss: 1.68 Accuracy 1.63%\n",
      "Loss: 1.69 Accuracy 1.63%\n",
      "Loss: 1.66 Accuracy 1.63%\n",
      "Loss: 1.67 Accuracy 1.64%\n",
      "Loss: 1.66 Accuracy 1.64%\n",
      "Loss: 1.68 Accuracy 1.65%\n",
      "Loss: 1.66 Accuracy 1.64%\n",
      "Loss: 1.64 Accuracy 1.64%\n",
      "Loss: 1.62 Accuracy 1.66%\n",
      "Loss: 1.65 Accuracy 1.66%\n",
      "Loss: 1.67 Accuracy 1.67%\n",
      "Loss: 1.65 Accuracy 1.68%\n",
      "Loss: 1.66 Accuracy 1.67%\n",
      "Loss: 1.66 Accuracy 1.67%\n",
      "Loss: 1.71 Accuracy 1.69%\n",
      "Loss: 1.71 Accuracy 1.69%\n",
      "Loss: 1.65 Accuracy 1.70%\n",
      "Loss: 1.65 Accuracy 1.70%\n",
      "Loss: 1.66 Accuracy 1.70%\n",
      "Loss: 1.67 Accuracy 1.71%\n",
      "Loss: 1.68 Accuracy 1.72%\n",
      "Loss: 1.67 Accuracy 1.73%\n",
      "Loss: 1.66 Accuracy 1.73%\n",
      "Loss: 1.67 Accuracy 1.73%\n",
      "Loss: 1.63 Accuracy 1.74%\n",
      "Loss: 1.65 Accuracy 1.75%\n",
      "Loss: 1.62 Accuracy 1.76%\n",
      "Loss: 1.64 Accuracy 1.76%\n",
      "Loss: 1.62 Accuracy 1.76%\n",
      "Loss: 1.67 Accuracy 1.76%\n",
      "Loss: 1.69 Accuracy 1.77%\n",
      "Loss: 1.66 Accuracy 1.79%\n",
      "Loss: 1.65 Accuracy 1.80%\n",
      "Loss: 1.67 Accuracy 1.80%\n",
      "Loss: 1.65 Accuracy 1.81%\n",
      "Loss: 1.65 Accuracy 1.80%\n",
      "Loss: 1.67 Accuracy 1.81%\n",
      "Loss: 1.66 Accuracy 1.81%\n",
      "Loss: 1.66 Accuracy 1.82%\n",
      "Loss: 1.61 Accuracy 1.81%\n",
      "Loss: 1.62 Accuracy 1.81%\n",
      "Loss: 1.70 Accuracy 1.82%\n",
      "Loss: 1.65 Accuracy 1.82%\n",
      "Loss: 1.63 Accuracy 1.83%\n",
      "Loss: 1.66 Accuracy 1.83%\n",
      "Loss: 1.70 Accuracy 1.84%\n",
      "Loss: 1.70 Accuracy 1.84%\n",
      "Loss: 1.68 Accuracy 1.84%\n",
      "Loss: 1.66 Accuracy 1.84%\n",
      "Loss: 1.63 Accuracy 1.85%\n",
      "Loss: 1.63 Accuracy 1.85%\n",
      "Loss: 1.64 Accuracy 1.85%\n",
      "Loss: 1.59 Accuracy 1.86%\n",
      "Loss: 1.65 Accuracy 1.86%\n",
      "Loss: 1.65 Accuracy 1.86%\n",
      "Loss: 1.62 Accuracy 1.86%\n",
      "Loss: 1.64 Accuracy 1.86%\n",
      "Loss: 1.65 Accuracy 1.87%\n",
      "Loss: 1.66 Accuracy 1.88%\n",
      "Loss: 1.64 Accuracy 1.88%\n",
      "Loss: 1.65 Accuracy 1.89%\n",
      "Loss: 1.63 Accuracy 1.89%\n",
      "Loss: 1.64 Accuracy 1.89%\n",
      "Loss: 1.64 Accuracy 1.90%\n",
      "Loss: 1.65 Accuracy 1.90%\n",
      "Loss: 1.62 Accuracy 1.91%\n",
      "Loss: 1.64 Accuracy 1.91%\n",
      "Loss: 1.61 Accuracy 1.92%\n",
      "Loss: 1.64 Accuracy 1.95%\n",
      "Loss: 1.64 Accuracy 1.96%\n",
      "Loss: 1.65 Accuracy 1.96%\n",
      "Loss: 1.63 Accuracy 1.97%\n",
      "Loss: 1.63 Accuracy 1.97%\n",
      "Loss: 1.61 Accuracy 1.97%\n",
      "Loss: 1.63 Accuracy 1.97%\n",
      "Loss: 1.60 Accuracy 1.98%\n",
      "Loss: 1.63 Accuracy 1.99%\n",
      "Loss: 1.60 Accuracy 1.99%\n",
      "Loss: 1.61 Accuracy 2.00%\n",
      "Loss: 1.63 Accuracy 2.01%\n",
      "Loss: 1.65 Accuracy 2.02%\n",
      "Loss: 1.62 Accuracy 2.03%\n",
      "Loss: 1.64 Accuracy 2.04%\n",
      "Loss: 1.63 Accuracy 2.04%\n",
      "Loss: 1.60 Accuracy 2.05%\n",
      "Loss: 1.58 Accuracy 2.06%\n",
      "Loss: 1.62 Accuracy 2.07%\n",
      "Loss: 1.60 Accuracy 2.08%\n",
      "Loss: 1.61 Accuracy 2.09%\n",
      "Loss: 1.65 Accuracy 2.09%\n",
      "Loss: 1.65 Accuracy 2.10%\n",
      "Loss: 1.63 Accuracy 2.10%\n",
      "Loss: 1.62 Accuracy 2.10%\n",
      "Loss: 1.60 Accuracy 2.11%\n",
      "Loss: 1.61 Accuracy 2.11%\n",
      "Loss: 1.63 Accuracy 2.12%\n",
      "Loss: 1.60 Accuracy 2.12%\n",
      "Loss: 1.61 Accuracy 2.12%\n",
      "Loss: 1.64 Accuracy 2.12%\n",
      "Loss: 1.59 Accuracy 2.12%\n",
      "Loss: 1.63 Accuracy 2.12%\n",
      "Loss: 1.66 Accuracy 2.13%\n",
      "Loss: 1.63 Accuracy 2.14%\n",
      "Loss: 1.64 Accuracy 2.15%\n",
      "Loss: 1.62 Accuracy 2.15%\n",
      "Loss: 1.61 Accuracy 2.16%\n",
      "Loss: 1.62 Accuracy 2.16%\n",
      "Loss: 1.62 Accuracy 2.17%\n",
      "Loss: 1.59 Accuracy 2.17%\n",
      "Loss: 1.59 Accuracy 2.18%\n",
      "Loss: 1.58 Accuracy 2.19%\n",
      "Loss: 1.61 Accuracy 2.19%\n",
      "Loss: 1.62 Accuracy 2.19%\n",
      "Loss: 1.60 Accuracy 2.20%\n",
      "Loss: 1.61 Accuracy 2.21%\n",
      "Loss: 1.60 Accuracy 2.22%\n",
      "Loss: 1.58 Accuracy 2.23%\n",
      "Loss: 1.59 Accuracy 2.23%\n",
      "Loss: 1.61 Accuracy 2.23%\n",
      "Loss: 1.57 Accuracy 2.26%\n",
      "Loss: 1.61 Accuracy 2.25%\n",
      "Loss: 1.60 Accuracy 2.26%\n",
      "Loss: 1.60 Accuracy 2.27%\n",
      "Loss: 1.60 Accuracy 2.27%\n",
      "Loss: 1.59 Accuracy 2.27%\n",
      "Loss: 1.61 Accuracy 2.27%\n",
      "Loss: 1.59 Accuracy 2.28%\n",
      "Loss: 1.59 Accuracy 2.29%\n",
      "Loss: 1.59 Accuracy 2.30%\n",
      "Loss: 1.59 Accuracy 2.31%\n",
      "Loss: 1.58 Accuracy 2.33%\n",
      "Loss: 1.60 Accuracy 2.34%\n",
      "Loss: 1.62 Accuracy 2.36%\n",
      "Loss: 1.62 Accuracy 2.36%\n",
      "Loss: 1.61 Accuracy 2.37%\n",
      "Loss: 1.58 Accuracy 2.38%\n",
      "Loss: 1.60 Accuracy 2.38%\n",
      "Loss: 1.58 Accuracy 2.39%\n",
      "Loss: 1.62 Accuracy 2.40%\n",
      "Loss: 1.59 Accuracy 2.39%\n",
      "Loss: 1.60 Accuracy 2.39%\n",
      "Loss: 1.57 Accuracy 2.40%\n",
      "Loss: 1.55 Accuracy 2.41%\n",
      "Loss: 1.57 Accuracy 2.41%\n",
      "Loss: 1.58 Accuracy 2.42%\n",
      "Loss: 1.58 Accuracy 2.42%\n",
      "Loss: 1.55 Accuracy 2.44%\n",
      "Loss: 1.56 Accuracy 2.45%\n",
      "Loss: 1.59 Accuracy 2.45%\n",
      "Loss: 1.59 Accuracy 2.46%\n",
      "Loss: 1.61 Accuracy 2.46%\n",
      "Loss: 1.60 Accuracy 2.46%\n",
      "Loss: 1.60 Accuracy 2.46%\n",
      "Loss: 1.60 Accuracy 2.47%\n",
      "Loss: 1.58 Accuracy 2.47%\n",
      "Loss: 1.59 Accuracy 2.47%\n",
      "Loss: 1.61 Accuracy 2.47%\n",
      "Loss: 1.58 Accuracy 2.48%\n",
      "Loss: 1.56 Accuracy 2.49%\n",
      "Loss: 1.59 Accuracy 2.50%\n",
      "Loss: 1.57 Accuracy 2.51%\n",
      "Loss: 1.58 Accuracy 2.52%\n",
      "Loss: 1.60 Accuracy 2.52%\n",
      "Loss: 1.58 Accuracy 2.52%\n",
      "Loss: 1.57 Accuracy 2.52%\n",
      "Loss: 1.57 Accuracy 2.53%\n",
      "Loss: 1.58 Accuracy 2.53%\n",
      "Loss: 1.58 Accuracy 2.54%\n",
      "Loss: 1.56 Accuracy 2.55%\n",
      "Loss: 1.57 Accuracy 2.56%\n",
      "Loss: 1.54 Accuracy 2.57%\n",
      "Loss: 1.54 Accuracy 2.57%\n",
      "Loss: 1.56 Accuracy 2.57%\n",
      "Loss: 1.58 Accuracy 2.58%\n",
      "Loss: 1.56 Accuracy 2.58%\n",
      "Loss: 1.56 Accuracy 2.59%\n",
      "Loss: 1.56 Accuracy 2.60%\n",
      "Test Accuracy: 30.17%\n",
      "Epoch 1\n",
      "Loss: 0.15 Accuracy 6.25%\n",
      "Loss: 1.08 Accuracy 4.26%\n",
      "Loss: 1.37 Accuracy 4.76%\n",
      "Loss: 1.51 Accuracy 4.13%\n",
      "Loss: 1.51 Accuracy 4.34%\n",
      "Loss: 1.54 Accuracy 4.29%\n",
      "Loss: 1.56 Accuracy 4.56%\n",
      "Loss: 1.57 Accuracy 4.58%\n",
      "Loss: 1.57 Accuracy 4.71%\n",
      "Loss: 1.53 Accuracy 4.84%\n",
      "Loss: 1.54 Accuracy 4.61%\n",
      "Loss: 1.56 Accuracy 4.67%\n",
      "Loss: 1.55 Accuracy 4.70%\n",
      "Loss: 1.52 Accuracy 4.91%\n",
      "Loss: 1.54 Accuracy 4.96%\n",
      "Loss: 1.54 Accuracy 4.99%\n",
      "Loss: 1.54 Accuracy 4.99%\n",
      "Loss: 1.51 Accuracy 5.04%\n",
      "Loss: 1.53 Accuracy 5.01%\n",
      "Loss: 1.56 Accuracy 5.01%\n",
      "Loss: 1.55 Accuracy 4.96%\n",
      "Loss: 1.52 Accuracy 5.02%\n",
      "Loss: 1.56 Accuracy 5.08%\n",
      "Loss: 1.52 Accuracy 5.17%\n",
      "Loss: 1.52 Accuracy 5.20%\n",
      "Loss: 1.56 Accuracy 5.24%\n",
      "Loss: 1.54 Accuracy 5.26%\n",
      "Loss: 1.54 Accuracy 5.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.54 Accuracy 5.34%\n",
      "Loss: 1.52 Accuracy 5.39%\n",
      "Loss: 1.52 Accuracy 5.39%\n",
      "Loss: 1.53 Accuracy 5.38%\n",
      "Loss: 1.56 Accuracy 5.48%\n",
      "Loss: 1.55 Accuracy 5.55%\n",
      "Loss: 1.53 Accuracy 5.57%\n",
      "Loss: 1.51 Accuracy 5.60%\n",
      "Loss: 1.51 Accuracy 5.64%\n",
      "Loss: 1.49 Accuracy 5.74%\n",
      "Loss: 1.51 Accuracy 5.71%\n",
      "Loss: 1.50 Accuracy 5.68%\n",
      "Loss: 1.52 Accuracy 5.73%\n",
      "Loss: 1.54 Accuracy 5.73%\n",
      "Loss: 1.52 Accuracy 5.74%\n",
      "Loss: 1.51 Accuracy 5.76%\n",
      "Loss: 1.49 Accuracy 5.81%\n",
      "Loss: 1.50 Accuracy 5.80%\n",
      "Loss: 1.50 Accuracy 5.80%\n",
      "Loss: 1.52 Accuracy 5.77%\n",
      "Loss: 1.55 Accuracy 5.78%\n",
      "Loss: 1.54 Accuracy 5.81%\n",
      "Loss: 1.51 Accuracy 5.83%\n",
      "Loss: 1.53 Accuracy 5.81%\n",
      "Loss: 1.52 Accuracy 5.81%\n",
      "Loss: 1.53 Accuracy 5.80%\n",
      "Loss: 1.52 Accuracy 5.78%\n",
      "Loss: 1.51 Accuracy 5.78%\n",
      "Loss: 1.54 Accuracy 5.75%\n",
      "Loss: 1.55 Accuracy 5.72%\n",
      "Loss: 1.51 Accuracy 5.72%\n",
      "Loss: 1.50 Accuracy 5.72%\n",
      "Loss: 1.51 Accuracy 5.69%\n",
      "Loss: 1.49 Accuracy 5.73%\n",
      "Loss: 1.53 Accuracy 5.75%\n",
      "Loss: 1.54 Accuracy 5.74%\n",
      "Loss: 1.54 Accuracy 5.75%\n",
      "Loss: 1.52 Accuracy 5.75%\n",
      "Loss: 1.52 Accuracy 5.75%\n",
      "Loss: 1.52 Accuracy 5.76%\n",
      "Loss: 1.53 Accuracy 5.77%\n",
      "Loss: 1.54 Accuracy 5.76%\n",
      "Loss: 1.52 Accuracy 5.77%\n",
      "Loss: 1.53 Accuracy 5.75%\n",
      "Loss: 1.53 Accuracy 5.75%\n",
      "Loss: 1.52 Accuracy 5.76%\n",
      "Loss: 1.50 Accuracy 5.78%\n",
      "Loss: 1.51 Accuracy 5.78%\n",
      "Loss: 1.51 Accuracy 5.79%\n",
      "Loss: 1.52 Accuracy 5.80%\n",
      "Loss: 1.56 Accuracy 5.80%\n",
      "Loss: 1.53 Accuracy 5.82%\n",
      "Loss: 1.56 Accuracy 5.82%\n",
      "Loss: 1.51 Accuracy 5.88%\n",
      "Loss: 1.51 Accuracy 5.89%\n",
      "Loss: 1.52 Accuracy 5.86%\n",
      "Loss: 1.52 Accuracy 5.88%\n",
      "Loss: 1.53 Accuracy 5.89%\n",
      "Loss: 1.52 Accuracy 5.87%\n",
      "Loss: 1.50 Accuracy 5.91%\n",
      "Loss: 1.53 Accuracy 5.91%\n",
      "Loss: 1.52 Accuracy 5.91%\n",
      "Loss: 1.54 Accuracy 5.91%\n",
      "Loss: 1.50 Accuracy 5.91%\n",
      "Loss: 1.52 Accuracy 5.92%\n",
      "Loss: 1.48 Accuracy 5.94%\n",
      "Loss: 1.52 Accuracy 5.92%\n",
      "Loss: 1.52 Accuracy 5.92%\n",
      "Loss: 1.54 Accuracy 5.92%\n",
      "Loss: 1.52 Accuracy 5.92%\n",
      "Loss: 1.50 Accuracy 5.93%\n",
      "Loss: 1.51 Accuracy 5.93%\n",
      "Loss: 1.50 Accuracy 5.92%\n",
      "Loss: 1.52 Accuracy 5.93%\n",
      "Loss: 1.55 Accuracy 5.93%\n",
      "Loss: 1.51 Accuracy 5.94%\n",
      "Loss: 1.58 Accuracy 5.92%\n",
      "Loss: 1.55 Accuracy 5.91%\n",
      "Loss: 1.51 Accuracy 5.93%\n",
      "Loss: 1.50 Accuracy 5.95%\n",
      "Loss: 1.50 Accuracy 5.95%\n",
      "Loss: 1.49 Accuracy 5.96%\n",
      "Loss: 1.48 Accuracy 5.96%\n",
      "Loss: 1.50 Accuracy 5.97%\n",
      "Loss: 1.54 Accuracy 5.95%\n",
      "Loss: 1.52 Accuracy 5.97%\n",
      "Loss: 1.49 Accuracy 5.98%\n",
      "Loss: 1.51 Accuracy 5.98%\n",
      "Loss: 1.48 Accuracy 6.01%\n",
      "Loss: 1.49 Accuracy 6.03%\n",
      "Loss: 1.51 Accuracy 6.02%\n",
      "Loss: 1.51 Accuracy 6.02%\n",
      "Loss: 1.52 Accuracy 6.02%\n",
      "Loss: 1.52 Accuracy 6.03%\n",
      "Loss: 1.51 Accuracy 6.03%\n",
      "Loss: 1.53 Accuracy 6.04%\n",
      "Loss: 1.50 Accuracy 6.04%\n",
      "Loss: 1.51 Accuracy 6.04%\n",
      "Loss: 1.50 Accuracy 6.04%\n",
      "Loss: 1.48 Accuracy 6.04%\n",
      "Loss: 1.50 Accuracy 6.02%\n",
      "Loss: 1.51 Accuracy 6.02%\n",
      "Loss: 1.52 Accuracy 6.01%\n",
      "Loss: 1.53 Accuracy 6.00%\n",
      "Loss: 1.49 Accuracy 6.01%\n",
      "Loss: 1.50 Accuracy 6.02%\n",
      "Loss: 1.52 Accuracy 6.03%\n",
      "Loss: 1.51 Accuracy 6.04%\n",
      "Loss: 1.52 Accuracy 6.04%\n",
      "Loss: 1.51 Accuracy 6.03%\n",
      "Loss: 1.49 Accuracy 6.04%\n",
      "Loss: 1.48 Accuracy 6.04%\n",
      "Loss: 1.48 Accuracy 6.06%\n",
      "Loss: 1.51 Accuracy 6.05%\n",
      "Loss: 1.49 Accuracy 6.05%\n",
      "Loss: 1.49 Accuracy 6.05%\n",
      "Loss: 1.48 Accuracy 6.05%\n",
      "Loss: 1.49 Accuracy 6.06%\n",
      "Loss: 1.49 Accuracy 6.06%\n",
      "Loss: 1.49 Accuracy 6.07%\n",
      "Loss: 1.51 Accuracy 6.07%\n",
      "Loss: 1.51 Accuracy 6.07%\n",
      "Loss: 1.50 Accuracy 6.08%\n",
      "Loss: 1.50 Accuracy 6.08%\n",
      "Loss: 1.50 Accuracy 6.07%\n",
      "Loss: 1.51 Accuracy 6.06%\n",
      "Loss: 1.50 Accuracy 6.07%\n",
      "Loss: 1.49 Accuracy 6.06%\n",
      "Loss: 1.49 Accuracy 6.08%\n",
      "Loss: 1.51 Accuracy 6.08%\n",
      "Loss: 1.50 Accuracy 6.09%\n",
      "Loss: 1.48 Accuracy 6.11%\n",
      "Loss: 1.44 Accuracy 6.13%\n",
      "Loss: 1.47 Accuracy 6.14%\n",
      "Loss: 1.51 Accuracy 6.15%\n",
      "Loss: 1.49 Accuracy 6.15%\n",
      "Loss: 1.49 Accuracy 6.16%\n",
      "Loss: 1.50 Accuracy 6.14%\n",
      "Loss: 1.49 Accuracy 6.15%\n",
      "Loss: 1.53 Accuracy 6.15%\n",
      "Loss: 1.52 Accuracy 6.14%\n",
      "Loss: 1.50 Accuracy 6.15%\n",
      "Loss: 1.54 Accuracy 6.14%\n",
      "Loss: 1.50 Accuracy 6.14%\n",
      "Loss: 1.50 Accuracy 6.17%\n",
      "Loss: 1.50 Accuracy 6.16%\n",
      "Loss: 1.50 Accuracy 6.16%\n",
      "Loss: 1.49 Accuracy 6.16%\n",
      "Loss: 1.51 Accuracy 6.18%\n",
      "Loss: 1.51 Accuracy 6.16%\n",
      "Loss: 1.50 Accuracy 6.17%\n",
      "Loss: 1.51 Accuracy 6.16%\n",
      "Loss: 1.53 Accuracy 6.17%\n",
      "Loss: 1.51 Accuracy 6.18%\n",
      "Loss: 1.48 Accuracy 6.18%\n",
      "Loss: 1.51 Accuracy 6.19%\n",
      "Loss: 1.48 Accuracy 6.20%\n",
      "Loss: 1.49 Accuracy 6.21%\n",
      "Loss: 1.49 Accuracy 6.21%\n",
      "Loss: 1.48 Accuracy 6.22%\n",
      "Loss: 1.49 Accuracy 6.22%\n",
      "Loss: 1.51 Accuracy 6.21%\n",
      "Loss: 1.46 Accuracy 6.22%\n",
      "Loss: 1.47 Accuracy 6.22%\n",
      "Loss: 1.48 Accuracy 6.23%\n",
      "Loss: 1.50 Accuracy 6.24%\n",
      "Loss: 1.47 Accuracy 6.25%\n",
      "Loss: 1.47 Accuracy 6.26%\n",
      "Loss: 1.47 Accuracy 6.26%\n",
      "Loss: 1.47 Accuracy 6.27%\n",
      "Loss: 1.49 Accuracy 6.28%\n",
      "Loss: 1.49 Accuracy 6.27%\n",
      "Loss: 1.50 Accuracy 6.27%\n",
      "Loss: 1.49 Accuracy 6.27%\n",
      "Loss: 1.48 Accuracy 6.27%\n",
      "Loss: 1.43 Accuracy 6.29%\n",
      "Loss: 1.51 Accuracy 6.29%\n",
      "Loss: 1.50 Accuracy 6.28%\n",
      "Loss: 1.50 Accuracy 6.29%\n",
      "Loss: 1.50 Accuracy 6.28%\n",
      "Loss: 1.48 Accuracy 6.28%\n",
      "Loss: 1.48 Accuracy 6.30%\n",
      "Loss: 1.49 Accuracy 6.30%\n",
      "Loss: 1.48 Accuracy 6.30%\n",
      "Loss: 1.45 Accuracy 6.31%\n",
      "Loss: 1.50 Accuracy 6.32%\n",
      "Loss: 1.46 Accuracy 6.32%\n",
      "Loss: 1.46 Accuracy 6.33%\n",
      "Loss: 1.48 Accuracy 6.33%\n",
      "Loss: 1.47 Accuracy 6.33%\n",
      "Loss: 1.49 Accuracy 6.34%\n",
      "Loss: 1.50 Accuracy 6.34%\n",
      "Loss: 1.55 Accuracy 6.32%\n",
      "Loss: 1.49 Accuracy 6.33%\n",
      "Loss: 1.48 Accuracy 6.33%\n",
      "Loss: 1.47 Accuracy 6.34%\n",
      "Loss: 1.51 Accuracy 6.34%\n",
      "Loss: 1.51 Accuracy 6.34%\n",
      "Loss: 1.50 Accuracy 6.35%\n",
      "Loss: 1.51 Accuracy 6.35%\n",
      "Loss: 1.51 Accuracy 6.35%\n",
      "Loss: 1.48 Accuracy 6.35%\n",
      "Loss: 1.50 Accuracy 6.35%\n",
      "Loss: 1.46 Accuracy 6.35%\n",
      "Loss: 1.47 Accuracy 6.36%\n",
      "Loss: 1.50 Accuracy 6.36%\n",
      "Loss: 1.46 Accuracy 6.37%\n",
      "Loss: 1.45 Accuracy 6.39%\n",
      "Loss: 1.47 Accuracy 6.39%\n",
      "Loss: 1.45 Accuracy 6.40%\n",
      "Loss: 1.46 Accuracy 6.40%\n",
      "Loss: 1.45 Accuracy 6.40%\n",
      "Loss: 1.43 Accuracy 6.42%\n",
      "Loss: 1.49 Accuracy 6.42%\n",
      "Loss: 1.50 Accuracy 6.41%\n",
      "Loss: 1.49 Accuracy 6.41%\n",
      "Loss: 1.48 Accuracy 6.41%\n",
      "Loss: 1.46 Accuracy 6.42%\n",
      "Loss: 1.45 Accuracy 6.43%\n",
      "Loss: 1.49 Accuracy 6.43%\n",
      "Loss: 1.46 Accuracy 6.44%\n",
      "Loss: 1.44 Accuracy 6.47%\n",
      "Loss: 1.47 Accuracy 6.47%\n",
      "Loss: 1.48 Accuracy 6.47%\n",
      "Loss: 1.47 Accuracy 6.48%\n",
      "Loss: 1.47 Accuracy 6.47%\n",
      "Loss: 1.48 Accuracy 6.48%\n",
      "Loss: 1.46 Accuracy 6.48%\n",
      "Loss: 1.45 Accuracy 6.49%\n",
      "Loss: 1.50 Accuracy 6.49%\n",
      "Loss: 1.49 Accuracy 6.50%\n",
      "Loss: 1.48 Accuracy 6.49%\n",
      "Loss: 1.46 Accuracy 6.49%\n",
      "Loss: 1.47 Accuracy 6.50%\n",
      "Loss: 1.47 Accuracy 6.50%\n",
      "Loss: 1.45 Accuracy 6.51%\n",
      "Loss: 1.47 Accuracy 6.51%\n",
      "Loss: 1.46 Accuracy 6.52%\n",
      "Loss: 1.46 Accuracy 6.53%\n",
      "Loss: 1.45 Accuracy 6.54%\n",
      "Loss: 1.45 Accuracy 6.55%\n",
      "Loss: 1.46 Accuracy 6.56%\n",
      "Loss: 1.48 Accuracy 6.56%\n",
      "Loss: 1.47 Accuracy 6.56%\n",
      "Loss: 1.48 Accuracy 6.56%\n",
      "Loss: 1.48 Accuracy 6.56%\n",
      "Loss: 1.51 Accuracy 6.56%\n",
      "Loss: 1.49 Accuracy 6.55%\n",
      "Loss: 1.49 Accuracy 6.56%\n",
      "Loss: 1.48 Accuracy 6.56%\n",
      "Loss: 1.44 Accuracy 6.57%\n",
      "Loss: 1.45 Accuracy 6.58%\n",
      "Loss: 1.47 Accuracy 6.58%\n",
      "Loss: 1.45 Accuracy 6.59%\n",
      "Loss: 1.45 Accuracy 6.59%\n",
      "Loss: 1.47 Accuracy 6.59%\n",
      "Loss: 1.47 Accuracy 6.59%\n",
      "Loss: 1.46 Accuracy 6.59%\n",
      "Test Accuracy: 49.95%\n",
      "Epoch 2\n",
      "Loss: 0.14 Accuracy 9.38%\n",
      "Loss: 1.01 Accuracy 7.39%\n",
      "Loss: 1.30 Accuracy 6.99%\n",
      "Loss: 1.36 Accuracy 7.76%\n",
      "Loss: 1.41 Accuracy 7.77%\n",
      "Loss: 1.43 Accuracy 7.72%\n",
      "Loss: 1.40 Accuracy 8.40%\n",
      "Loss: 1.46 Accuracy 8.10%\n",
      "Loss: 1.41 Accuracy 8.41%\n",
      "Loss: 1.39 Accuracy 8.86%\n",
      "Loss: 1.41 Accuracy 9.03%\n",
      "Loss: 1.43 Accuracy 9.01%\n",
      "Loss: 1.43 Accuracy 8.88%\n",
      "Loss: 1.44 Accuracy 8.80%\n",
      "Loss: 1.40 Accuracy 8.89%\n",
      "Loss: 1.41 Accuracy 9.02%\n",
      "Loss: 1.43 Accuracy 8.99%\n",
      "Loss: 1.43 Accuracy 9.03%\n",
      "Loss: 1.42 Accuracy 9.01%\n",
      "Loss: 1.42 Accuracy 9.03%\n",
      "Loss: 1.42 Accuracy 9.08%\n",
      "Loss: 1.41 Accuracy 9.12%\n",
      "Loss: 1.39 Accuracy 9.26%\n",
      "Loss: 1.41 Accuracy 9.27%\n",
      "Loss: 1.41 Accuracy 9.32%\n",
      "Loss: 1.41 Accuracy 9.29%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.40 Accuracy 9.32%\n",
      "Loss: 1.41 Accuracy 9.35%\n",
      "Loss: 1.39 Accuracy 9.44%\n",
      "Loss: 1.40 Accuracy 9.48%\n",
      "Loss: 1.42 Accuracy 9.47%\n",
      "Loss: 1.40 Accuracy 9.49%\n",
      "Loss: 1.41 Accuracy 9.47%\n",
      "Loss: 1.42 Accuracy 9.43%\n",
      "Loss: 1.42 Accuracy 9.41%\n",
      "Loss: 1.46 Accuracy 9.35%\n",
      "Loss: 1.42 Accuracy 9.36%\n",
      "Loss: 1.41 Accuracy 9.36%\n",
      "Loss: 1.42 Accuracy 9.35%\n",
      "Loss: 1.43 Accuracy 9.32%\n",
      "Loss: 1.46 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.28%\n",
      "Loss: 1.41 Accuracy 9.30%\n",
      "Loss: 1.40 Accuracy 9.30%\n",
      "Loss: 1.42 Accuracy 9.32%\n",
      "Loss: 1.42 Accuracy 9.35%\n",
      "Loss: 1.43 Accuracy 9.34%\n",
      "Loss: 1.45 Accuracy 9.32%\n",
      "Loss: 1.40 Accuracy 9.37%\n",
      "Loss: 1.41 Accuracy 9.38%\n",
      "Loss: 1.45 Accuracy 9.31%\n",
      "Loss: 1.44 Accuracy 9.30%\n",
      "Loss: 1.45 Accuracy 9.29%\n",
      "Loss: 1.46 Accuracy 9.24%\n",
      "Loss: 1.45 Accuracy 9.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.43 Accuracy 9.22%\n",
      "Loss: 1.41 Accuracy 9.24%\n",
      "Loss: 1.42 Accuracy 9.24%\n",
      "Loss: 1.47 Accuracy 9.20%\n",
      "Loss: 1.42 Accuracy 9.21%\n",
      "Loss: 1.42 Accuracy 9.20%\n",
      "Loss: 1.41 Accuracy 9.21%\n",
      "Loss: 1.41 Accuracy 9.22%\n",
      "Loss: 1.41 Accuracy 9.22%\n",
      "Loss: 1.43 Accuracy 9.25%\n",
      "Loss: 1.41 Accuracy 9.27%\n",
      "Loss: 1.44 Accuracy 9.25%\n",
      "Loss: 1.43 Accuracy 9.24%\n",
      "Loss: 1.43 Accuracy 9.24%\n",
      "Loss: 1.44 Accuracy 9.25%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.43 Accuracy 9.26%\n",
      "Loss: 1.41 Accuracy 9.26%\n",
      "Loss: 1.40 Accuracy 9.27%\n",
      "Loss: 1.41 Accuracy 9.28%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.43 Accuracy 9.24%\n",
      "Loss: 1.41 Accuracy 9.26%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.38 Accuracy 9.31%\n",
      "Loss: 1.39 Accuracy 9.33%\n",
      "Loss: 1.39 Accuracy 9.34%\n",
      "Loss: 1.42 Accuracy 9.32%\n",
      "Loss: 1.44 Accuracy 9.31%\n",
      "Loss: 1.43 Accuracy 9.32%\n",
      "Loss: 1.43 Accuracy 9.29%\n",
      "Loss: 1.45 Accuracy 9.29%\n",
      "Loss: 1.45 Accuracy 9.28%\n",
      "Loss: 1.42 Accuracy 9.28%\n",
      "Loss: 1.44 Accuracy 9.29%\n",
      "Loss: 1.42 Accuracy 9.29%\n",
      "Loss: 1.43 Accuracy 9.29%\n",
      "Loss: 1.42 Accuracy 9.28%\n",
      "Loss: 1.40 Accuracy 9.29%\n",
      "Loss: 1.41 Accuracy 9.31%\n",
      "Loss: 1.40 Accuracy 9.32%\n",
      "Loss: 1.42 Accuracy 9.32%\n",
      "Loss: 1.42 Accuracy 9.30%\n",
      "Loss: 1.42 Accuracy 9.32%\n",
      "Loss: 1.41 Accuracy 9.33%\n",
      "Loss: 1.45 Accuracy 9.31%\n",
      "Loss: 1.46 Accuracy 9.29%\n",
      "Loss: 1.47 Accuracy 9.26%\n",
      "Loss: 1.46 Accuracy 9.27%\n",
      "Loss: 1.44 Accuracy 9.25%\n",
      "Loss: 1.46 Accuracy 9.22%\n",
      "Loss: 1.43 Accuracy 9.21%\n",
      "Loss: 1.43 Accuracy 9.21%\n",
      "Loss: 1.41 Accuracy 9.23%\n",
      "Loss: 1.42 Accuracy 9.23%\n",
      "Loss: 1.39 Accuracy 9.24%\n",
      "Loss: 1.40 Accuracy 9.23%\n",
      "Loss: 1.39 Accuracy 9.25%\n",
      "Loss: 1.39 Accuracy 9.25%\n",
      "Loss: 1.42 Accuracy 9.24%\n",
      "Loss: 1.43 Accuracy 9.22%\n",
      "Loss: 1.42 Accuracy 9.22%\n",
      "Loss: 1.44 Accuracy 9.20%\n",
      "Loss: 1.41 Accuracy 9.20%\n",
      "Loss: 1.43 Accuracy 9.19%\n",
      "Loss: 1.45 Accuracy 9.19%\n",
      "Loss: 1.45 Accuracy 9.17%\n",
      "Loss: 1.45 Accuracy 9.15%\n",
      "Loss: 1.43 Accuracy 9.13%\n",
      "Loss: 1.42 Accuracy 9.12%\n",
      "Loss: 1.43 Accuracy 9.11%\n",
      "Loss: 1.44 Accuracy 9.11%\n",
      "Loss: 1.46 Accuracy 9.11%\n",
      "Loss: 1.47 Accuracy 9.10%\n",
      "Loss: 1.45 Accuracy 9.10%\n",
      "Loss: 1.43 Accuracy 9.12%\n",
      "Loss: 1.44 Accuracy 9.11%\n",
      "Loss: 1.42 Accuracy 9.11%\n",
      "Loss: 1.41 Accuracy 9.11%\n",
      "Loss: 1.42 Accuracy 9.11%\n",
      "Loss: 1.41 Accuracy 9.12%\n",
      "Loss: 1.41 Accuracy 9.12%\n",
      "Loss: 1.38 Accuracy 9.14%\n",
      "Loss: 1.42 Accuracy 9.12%\n",
      "Loss: 1.42 Accuracy 9.12%\n",
      "Loss: 1.42 Accuracy 9.14%\n",
      "Loss: 1.40 Accuracy 9.15%\n",
      "Loss: 1.41 Accuracy 9.15%\n",
      "Loss: 1.44 Accuracy 9.14%\n",
      "Loss: 1.42 Accuracy 9.15%\n",
      "Loss: 1.41 Accuracy 9.15%\n",
      "Loss: 1.42 Accuracy 9.14%\n",
      "Loss: 1.41 Accuracy 9.15%\n",
      "Loss: 1.42 Accuracy 9.14%\n",
      "Loss: 1.43 Accuracy 9.13%\n",
      "Loss: 1.44 Accuracy 9.11%\n",
      "Loss: 1.43 Accuracy 9.12%\n",
      "Loss: 1.45 Accuracy 9.11%\n",
      "Loss: 1.50 Accuracy 9.09%\n",
      "Loss: 1.46 Accuracy 9.08%\n",
      "Loss: 1.43 Accuracy 9.09%\n",
      "Loss: 1.41 Accuracy 9.11%\n",
      "Loss: 1.41 Accuracy 9.10%\n",
      "Loss: 1.42 Accuracy 9.12%\n",
      "Loss: 1.42 Accuracy 9.12%\n",
      "Loss: 1.40 Accuracy 9.13%\n",
      "Loss: 1.40 Accuracy 9.13%\n",
      "Loss: 1.40 Accuracy 9.14%\n",
      "Loss: 1.41 Accuracy 9.14%\n",
      "Loss: 1.42 Accuracy 9.14%\n",
      "Loss: 1.39 Accuracy 9.16%\n",
      "Loss: 1.40 Accuracy 9.17%\n",
      "Loss: 1.41 Accuracy 9.19%\n",
      "Loss: 1.41 Accuracy 9.19%\n",
      "Loss: 1.41 Accuracy 9.18%\n",
      "Loss: 1.43 Accuracy 9.17%\n",
      "Loss: 1.44 Accuracy 9.16%\n",
      "Loss: 1.44 Accuracy 9.15%\n",
      "Loss: 1.43 Accuracy 9.15%\n",
      "Loss: 1.42 Accuracy 9.15%\n",
      "Loss: 1.43 Accuracy 9.15%\n",
      "Loss: 1.45 Accuracy 9.13%\n",
      "Loss: 1.43 Accuracy 9.13%\n",
      "Loss: 1.41 Accuracy 9.13%\n",
      "Loss: 1.41 Accuracy 9.14%\n",
      "Loss: 1.42 Accuracy 9.14%\n",
      "Loss: 1.41 Accuracy 9.14%\n",
      "Loss: 1.41 Accuracy 9.16%\n",
      "Loss: 1.42 Accuracy 9.16%\n",
      "Loss: 1.38 Accuracy 9.18%\n",
      "Loss: 1.39 Accuracy 9.18%\n",
      "Loss: 1.39 Accuracy 9.19%\n",
      "Loss: 1.42 Accuracy 9.18%\n",
      "Loss: 1.43 Accuracy 9.17%\n",
      "Loss: 1.42 Accuracy 9.17%\n",
      "Loss: 1.43 Accuracy 9.16%\n",
      "Loss: 1.43 Accuracy 9.16%\n",
      "Loss: 1.43 Accuracy 9.15%\n",
      "Loss: 1.41 Accuracy 9.15%\n",
      "Loss: 1.40 Accuracy 9.16%\n",
      "Loss: 1.43 Accuracy 9.16%\n",
      "Loss: 1.41 Accuracy 9.17%\n",
      "Loss: 1.41 Accuracy 9.18%\n",
      "Loss: 1.40 Accuracy 9.18%\n",
      "Loss: 1.36 Accuracy 9.19%\n",
      "Loss: 1.41 Accuracy 9.19%\n",
      "Loss: 1.42 Accuracy 9.19%\n",
      "Loss: 1.41 Accuracy 9.20%\n",
      "Loss: 1.39 Accuracy 9.21%\n",
      "Loss: 1.40 Accuracy 9.21%\n",
      "Loss: 1.43 Accuracy 9.22%\n",
      "Loss: 1.42 Accuracy 9.21%\n",
      "Loss: 1.41 Accuracy 9.21%\n",
      "Loss: 1.40 Accuracy 9.21%\n",
      "Loss: 1.40 Accuracy 9.21%\n",
      "Loss: 1.39 Accuracy 9.22%\n",
      "Loss: 1.39 Accuracy 9.22%\n",
      "Loss: 1.43 Accuracy 9.21%\n",
      "Loss: 1.41 Accuracy 9.22%\n",
      "Loss: 1.38 Accuracy 9.23%\n",
      "Loss: 1.41 Accuracy 9.23%\n",
      "Loss: 1.42 Accuracy 9.24%\n",
      "Loss: 1.38 Accuracy 9.25%\n",
      "Loss: 1.42 Accuracy 9.24%\n",
      "Loss: 1.40 Accuracy 9.25%\n",
      "Loss: 1.42 Accuracy 9.24%\n",
      "Loss: 1.43 Accuracy 9.23%\n",
      "Loss: 1.41 Accuracy 9.23%\n",
      "Loss: 1.42 Accuracy 9.23%\n",
      "Loss: 1.39 Accuracy 9.24%\n",
      "Loss: 1.37 Accuracy 9.25%\n",
      "Loss: 1.39 Accuracy 9.25%\n",
      "Loss: 1.41 Accuracy 9.25%\n",
      "Loss: 1.41 Accuracy 9.25%\n",
      "Loss: 1.44 Accuracy 9.23%\n",
      "Loss: 1.41 Accuracy 9.23%\n",
      "Loss: 1.43 Accuracy 9.23%\n",
      "Loss: 1.42 Accuracy 9.23%\n",
      "Loss: 1.41 Accuracy 9.22%\n",
      "Loss: 1.39 Accuracy 9.23%\n",
      "Loss: 1.40 Accuracy 9.23%\n",
      "Loss: 1.39 Accuracy 9.24%\n",
      "Loss: 1.40 Accuracy 9.24%\n",
      "Loss: 1.38 Accuracy 9.24%\n",
      "Loss: 1.38 Accuracy 9.24%\n",
      "Loss: 1.39 Accuracy 9.25%\n",
      "Loss: 1.39 Accuracy 9.26%\n",
      "Loss: 1.44 Accuracy 9.26%\n",
      "Loss: 1.40 Accuracy 9.26%\n",
      "Loss: 1.41 Accuracy 9.26%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.40 Accuracy 9.27%\n",
      "Loss: 1.39 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.26%\n",
      "Loss: 1.39 Accuracy 9.27%\n",
      "Loss: 1.41 Accuracy 9.28%\n",
      "Loss: 1.43 Accuracy 9.26%\n",
      "Loss: 1.45 Accuracy 9.27%\n",
      "Loss: 1.43 Accuracy 9.26%\n",
      "Loss: 1.41 Accuracy 9.26%\n",
      "Loss: 1.42 Accuracy 9.25%\n",
      "Loss: 1.42 Accuracy 9.25%\n",
      "Loss: 1.39 Accuracy 9.25%\n",
      "Loss: 1.38 Accuracy 9.26%\n",
      "Loss: 1.39 Accuracy 9.28%\n",
      "Loss: 1.43 Accuracy 9.28%\n",
      "Loss: 1.43 Accuracy 9.27%\n",
      "Loss: 1.39 Accuracy 9.28%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.41 Accuracy 9.28%\n",
      "Loss: 1.43 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.44 Accuracy 9.27%\n",
      "Loss: 1.45 Accuracy 9.26%\n",
      "Loss: 1.41 Accuracy 9.26%\n",
      "Loss: 1.39 Accuracy 9.27%\n",
      "Loss: 1.40 Accuracy 9.26%\n",
      "Loss: 1.37 Accuracy 9.28%\n",
      "Loss: 1.40 Accuracy 9.27%\n",
      "Loss: 1.41 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.42 Accuracy 9.27%\n",
      "Loss: 1.38 Accuracy 9.28%\n",
      "Loss: 1.40 Accuracy 9.29%\n",
      "Loss: 1.41 Accuracy 9.29%\n",
      "Loss: 1.40 Accuracy 9.29%\n",
      "Loss: 1.45 Accuracy 9.28%\n",
      "Loss: 1.41 Accuracy 9.29%\n",
      "Test Accuracy: 56.79%\n",
      "Epoch 3\n",
      "Loss: 0.14 Accuracy 3.12%\n",
      "Loss: 0.95 Accuracy 9.09%\n",
      "Loss: 1.23 Accuracy 10.12%\n",
      "Loss: 1.38 Accuracy 9.07%\n",
      "Loss: 1.37 Accuracy 9.45%\n",
      "Loss: 1.38 Accuracy 9.68%\n",
      "Loss: 1.39 Accuracy 9.48%\n",
      "Loss: 1.38 Accuracy 9.55%\n",
      "Loss: 1.38 Accuracy 9.80%\n",
      "Loss: 1.40 Accuracy 9.55%\n",
      "Loss: 1.36 Accuracy 9.81%\n",
      "Loss: 1.37 Accuracy 9.83%\n",
      "Loss: 1.36 Accuracy 9.84%\n",
      "Loss: 1.37 Accuracy 9.90%\n",
      "Loss: 1.35 Accuracy 10.02%\n",
      "Loss: 1.34 Accuracy 10.24%\n",
      "Loss: 1.35 Accuracy 10.23%\n",
      "Loss: 1.39 Accuracy 10.05%\n",
      "Loss: 1.33 Accuracy 10.36%\n",
      "Loss: 1.36 Accuracy 10.34%\n",
      "Loss: 1.38 Accuracy 10.32%\n",
      "Loss: 1.38 Accuracy 10.25%\n",
      "Loss: 1.35 Accuracy 10.35%\n",
      "Loss: 1.38 Accuracy 10.29%\n",
      "Loss: 1.38 Accuracy 10.30%\n",
      "Loss: 1.35 Accuracy 10.38%\n",
      "Loss: 1.37 Accuracy 10.33%\n",
      "Loss: 1.40 Accuracy 10.24%\n",
      "Loss: 1.33 Accuracy 10.41%\n",
      "Loss: 1.39 Accuracy 10.36%\n",
      "Loss: 1.40 Accuracy 10.34%\n",
      "Loss: 1.39 Accuracy 10.30%\n",
      "Loss: 1.36 Accuracy 10.44%\n",
      "Loss: 1.35 Accuracy 10.51%\n",
      "Loss: 1.32 Accuracy 10.64%\n",
      "Loss: 1.36 Accuracy 10.59%\n",
      "Loss: 1.35 Accuracy 10.64%\n",
      "Loss: 1.35 Accuracy 10.66%\n",
      "Loss: 1.38 Accuracy 10.61%\n",
      "Loss: 1.37 Accuracy 10.64%\n",
      "Loss: 1.33 Accuracy 10.74%\n",
      "Loss: 1.36 Accuracy 10.73%\n",
      "Loss: 1.39 Accuracy 10.73%\n",
      "Loss: 1.39 Accuracy 10.70%\n",
      "Loss: 1.39 Accuracy 10.68%\n",
      "Loss: 1.40 Accuracy 10.65%\n",
      "Loss: 1.38 Accuracy 10.66%\n",
      "Loss: 1.38 Accuracy 10.64%\n",
      "Loss: 1.34 Accuracy 10.69%\n",
      "Loss: 1.38 Accuracy 10.68%\n",
      "Loss: 1.35 Accuracy 10.72%\n",
      "Loss: 1.36 Accuracy 10.70%\n",
      "Loss: 1.35 Accuracy 10.72%\n",
      "Loss: 1.37 Accuracy 10.70%\n",
      "Loss: 1.41 Accuracy 10.66%\n",
      "Loss: 1.41 Accuracy 10.62%\n",
      "Loss: 1.43 Accuracy 10.57%\n",
      "Loss: 1.42 Accuracy 10.58%\n",
      "Loss: 1.38 Accuracy 10.60%\n",
      "Loss: 1.37 Accuracy 10.62%\n",
      "Loss: 1.36 Accuracy 10.65%\n",
      "Loss: 1.36 Accuracy 10.68%\n",
      "Loss: 1.37 Accuracy 10.69%\n",
      "Loss: 1.35 Accuracy 10.72%\n",
      "Loss: 1.33 Accuracy 10.77%\n",
      "Loss: 1.38 Accuracy 10.73%\n",
      "Loss: 1.37 Accuracy 10.74%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.35 Accuracy 10.77%\n",
      "Loss: 1.35 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.37 Accuracy 10.78%\n",
      "Loss: 1.37 Accuracy 10.77%\n",
      "Loss: 1.36 Accuracy 10.79%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.36 Accuracy 10.78%\n",
      "Loss: 1.36 Accuracy 10.78%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.36 Accuracy 10.76%\n",
      "Loss: 1.38 Accuracy 10.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.36 Accuracy 10.76%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.37 Accuracy 10.78%\n",
      "Loss: 1.38 Accuracy 10.79%\n",
      "Loss: 1.35 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.78%\n",
      "Loss: 1.35 Accuracy 10.81%\n",
      "Loss: 1.34 Accuracy 10.83%\n",
      "Loss: 1.39 Accuracy 10.79%\n",
      "Loss: 1.35 Accuracy 10.82%\n",
      "Loss: 1.36 Accuracy 10.82%\n",
      "Loss: 1.38 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.79%\n",
      "Loss: 1.36 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.79%\n",
      "Loss: 1.40 Accuracy 10.76%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.36 Accuracy 10.78%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.38 Accuracy 10.77%\n",
      "Loss: 1.37 Accuracy 10.78%\n",
      "Loss: 1.34 Accuracy 10.82%\n",
      "Loss: 1.36 Accuracy 10.81%\n",
      "Loss: 1.38 Accuracy 10.81%\n",
      "Loss: 1.35 Accuracy 10.82%\n",
      "Loss: 1.30 Accuracy 10.86%\n",
      "Loss: 1.34 Accuracy 10.85%\n",
      "Loss: 1.37 Accuracy 10.84%\n",
      "Loss: 1.35 Accuracy 10.85%\n",
      "Loss: 1.37 Accuracy 10.84%\n",
      "Loss: 1.38 Accuracy 10.84%\n",
      "Loss: 1.38 Accuracy 10.83%\n",
      "Loss: 1.36 Accuracy 10.85%\n",
      "Loss: 1.35 Accuracy 10.86%\n",
      "Loss: 1.37 Accuracy 10.84%\n",
      "Loss: 1.39 Accuracy 10.81%\n",
      "Loss: 1.39 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.80%\n",
      "Loss: 1.42 Accuracy 10.78%\n",
      "Loss: 1.39 Accuracy 10.78%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.34 Accuracy 10.80%\n",
      "Loss: 1.36 Accuracy 10.79%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.36 Accuracy 10.78%\n",
      "Loss: 1.34 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.35 Accuracy 10.81%\n",
      "Loss: 1.38 Accuracy 10.77%\n",
      "Loss: 1.36 Accuracy 10.78%\n",
      "Loss: 1.38 Accuracy 10.77%\n",
      "Loss: 1.35 Accuracy 10.78%\n",
      "Loss: 1.35 Accuracy 10.79%\n",
      "Loss: 1.36 Accuracy 10.79%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.35 Accuracy 10.79%\n",
      "Loss: 1.40 Accuracy 10.77%\n",
      "Loss: 1.35 Accuracy 10.79%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.39 Accuracy 10.77%\n",
      "Loss: 1.38 Accuracy 10.77%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.41 Accuracy 10.73%\n",
      "Loss: 1.39 Accuracy 10.74%\n",
      "Loss: 1.37 Accuracy 10.75%\n",
      "Loss: 1.41 Accuracy 10.73%\n",
      "Loss: 1.40 Accuracy 10.73%\n",
      "Loss: 1.36 Accuracy 10.74%\n",
      "Loss: 1.36 Accuracy 10.75%\n",
      "Loss: 1.36 Accuracy 10.77%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.34 Accuracy 10.77%\n",
      "Loss: 1.33 Accuracy 10.79%\n",
      "Loss: 1.35 Accuracy 10.80%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.38 Accuracy 10.77%\n",
      "Loss: 1.36 Accuracy 10.79%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.35 Accuracy 10.81%\n",
      "Loss: 1.37 Accuracy 10.81%\n",
      "Loss: 1.34 Accuracy 10.82%\n",
      "Loss: 1.37 Accuracy 10.82%\n",
      "Loss: 1.36 Accuracy 10.82%\n",
      "Loss: 1.35 Accuracy 10.83%\n",
      "Loss: 1.36 Accuracy 10.83%\n",
      "Loss: 1.40 Accuracy 10.81%\n",
      "Loss: 1.39 Accuracy 10.80%\n",
      "Loss: 1.36 Accuracy 10.81%\n",
      "Loss: 1.38 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.37 Accuracy 10.80%\n",
      "Loss: 1.37 Accuracy 10.80%\n",
      "Loss: 1.33 Accuracy 10.82%\n",
      "Loss: 1.34 Accuracy 10.83%\n",
      "Loss: 1.38 Accuracy 10.82%\n",
      "Loss: 1.36 Accuracy 10.82%\n",
      "Loss: 1.36 Accuracy 10.82%\n",
      "Loss: 1.41 Accuracy 10.80%\n",
      "Loss: 1.41 Accuracy 10.78%\n",
      "Loss: 1.39 Accuracy 10.78%\n",
      "Loss: 1.37 Accuracy 10.79%\n",
      "Loss: 1.38 Accuracy 10.78%\n",
      "Loss: 1.35 Accuracy 10.78%\n",
      "Loss: 1.42 Accuracy 10.76%\n",
      "Loss: 1.42 Accuracy 10.76%\n",
      "Loss: 1.35 Accuracy 10.77%\n",
      "Loss: 1.37 Accuracy 10.77%\n",
      "Loss: 1.39 Accuracy 10.76%\n",
      "Loss: 1.40 Accuracy 10.75%\n",
      "Loss: 1.40 Accuracy 10.74%\n",
      "Loss: 1.38 Accuracy 10.74%\n",
      "Loss: 1.39 Accuracy 10.73%\n",
      "Loss: 1.41 Accuracy 10.72%\n",
      "Loss: 1.38 Accuracy 10.72%\n",
      "Loss: 1.38 Accuracy 10.72%\n",
      "Loss: 1.36 Accuracy 10.72%\n",
      "Loss: 1.39 Accuracy 10.71%\n",
      "Loss: 1.35 Accuracy 10.72%\n",
      "Loss: 1.36 Accuracy 10.72%\n",
      "Loss: 1.37 Accuracy 10.72%\n",
      "Loss: 1.36 Accuracy 10.73%\n",
      "Loss: 1.37 Accuracy 10.73%\n",
      "Loss: 1.38 Accuracy 10.73%\n",
      "Loss: 1.39 Accuracy 10.73%\n",
      "Loss: 1.39 Accuracy 10.72%\n",
      "Loss: 1.38 Accuracy 10.71%\n",
      "Loss: 1.36 Accuracy 10.72%\n",
      "Loss: 1.36 Accuracy 10.72%\n",
      "Loss: 1.34 Accuracy 10.73%\n",
      "Loss: 1.37 Accuracy 10.73%\n",
      "Loss: 1.36 Accuracy 10.74%\n",
      "Loss: 1.38 Accuracy 10.73%\n",
      "Loss: 1.35 Accuracy 10.74%\n",
      "Loss: 1.39 Accuracy 10.73%\n",
      "Loss: 1.41 Accuracy 10.72%\n",
      "Loss: 1.39 Accuracy 10.71%\n",
      "Loss: 1.42 Accuracy 10.70%\n",
      "Loss: 1.38 Accuracy 10.70%\n",
      "Loss: 1.39 Accuracy 10.69%\n",
      "Loss: 1.36 Accuracy 10.69%\n",
      "Loss: 1.34 Accuracy 10.70%\n",
      "Loss: 1.36 Accuracy 10.71%\n",
      "Loss: 1.38 Accuracy 10.70%\n",
      "Loss: 1.40 Accuracy 10.69%\n",
      "Loss: 1.40 Accuracy 10.69%\n",
      "Loss: 1.39 Accuracy 10.69%\n",
      "Loss: 1.37 Accuracy 10.70%\n",
      "Loss: 1.39 Accuracy 10.69%\n",
      "Loss: 1.41 Accuracy 10.69%\n",
      "Loss: 1.40 Accuracy 10.68%\n",
      "Loss: 1.39 Accuracy 10.68%\n",
      "Loss: 1.38 Accuracy 10.68%\n",
      "Loss: 1.39 Accuracy 10.67%\n",
      "Loss: 1.38 Accuracy 10.67%\n",
      "Loss: 1.38 Accuracy 10.67%\n",
      "Loss: 1.36 Accuracy 10.68%\n",
      "Loss: 1.36 Accuracy 10.68%\n",
      "Loss: 1.33 Accuracy 10.69%\n",
      "Loss: 1.34 Accuracy 10.70%\n",
      "Loss: 1.37 Accuracy 10.69%\n",
      "Loss: 1.38 Accuracy 10.69%\n",
      "Loss: 1.35 Accuracy 10.69%\n",
      "Loss: 1.36 Accuracy 10.69%\n",
      "Loss: 1.36 Accuracy 10.69%\n",
      "Loss: 1.36 Accuracy 10.69%\n",
      "Loss: 1.35 Accuracy 10.69%\n",
      "Loss: 1.36 Accuracy 10.70%\n",
      "Loss: 1.37 Accuracy 10.70%\n",
      "Loss: 1.36 Accuracy 10.71%\n",
      "Loss: 1.33 Accuracy 10.72%\n",
      "Loss: 1.34 Accuracy 10.73%\n",
      "Loss: 1.34 Accuracy 10.74%\n",
      "Loss: 1.36 Accuracy 10.74%\n",
      "Loss: 1.35 Accuracy 10.75%\n",
      "Loss: 1.35 Accuracy 10.75%\n",
      "Loss: 1.35 Accuracy 10.75%\n",
      "Loss: 1.36 Accuracy 10.75%\n",
      "Loss: 1.33 Accuracy 10.76%\n",
      "Loss: 1.37 Accuracy 10.76%\n",
      "Loss: 1.37 Accuracy 10.75%\n",
      "Loss: 1.35 Accuracy 10.76%\n",
      "Loss: 1.38 Accuracy 10.75%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.38 Accuracy 10.75%\n",
      "Loss: 1.40 Accuracy 10.74%\n",
      "Loss: 1.35 Accuracy 10.75%\n",
      "Loss: 1.35 Accuracy 10.75%\n",
      "Loss: 1.35 Accuracy 10.76%\n",
      "Loss: 1.35 Accuracy 10.76%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.39 Accuracy 10.75%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.38 Accuracy 10.76%\n",
      "Loss: 1.36 Accuracy 10.76%\n",
      "Loss: 1.35 Accuracy 10.76%\n",
      "Test Accuracy: 58.53%\n",
      "Epoch 4\n",
      "Loss: 0.14 Accuracy 15.62%\n",
      "Loss: 0.93 Accuracy 11.65%\n",
      "Loss: 1.17 Accuracy 12.95%\n",
      "Loss: 1.30 Accuracy 12.10%\n",
      "Loss: 1.33 Accuracy 12.35%\n",
      "Loss: 1.32 Accuracy 12.62%\n",
      "Loss: 1.30 Accuracy 12.96%\n",
      "Loss: 1.31 Accuracy 12.90%\n",
      "Loss: 1.33 Accuracy 12.89%\n",
      "Loss: 1.34 Accuracy 12.71%\n",
      "Loss: 1.34 Accuracy 12.53%\n",
      "Loss: 1.38 Accuracy 12.16%\n",
      "Loss: 1.34 Accuracy 12.24%\n",
      "Loss: 1.38 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 11.95%\n",
      "Loss: 1.34 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 11.92%\n",
      "Loss: 1.35 Accuracy 11.86%\n",
      "Loss: 1.36 Accuracy 11.90%\n",
      "Loss: 1.39 Accuracy 11.68%\n",
      "Loss: 1.37 Accuracy 11.58%\n",
      "Loss: 1.38 Accuracy 11.45%\n",
      "Loss: 1.38 Accuracy 11.41%\n",
      "Loss: 1.36 Accuracy 11.39%\n",
      "Loss: 1.33 Accuracy 11.46%\n",
      "Loss: 1.37 Accuracy 11.42%\n",
      "Loss: 1.33 Accuracy 11.54%\n",
      "Loss: 1.36 Accuracy 11.43%\n",
      "Loss: 1.36 Accuracy 11.39%\n",
      "Loss: 1.36 Accuracy 11.38%\n",
      "Loss: 1.37 Accuracy 11.35%\n",
      "Loss: 1.36 Accuracy 11.33%\n",
      "Loss: 1.35 Accuracy 11.33%\n",
      "Loss: 1.33 Accuracy 11.36%\n",
      "Loss: 1.32 Accuracy 11.43%\n",
      "Loss: 1.30 Accuracy 11.52%\n",
      "Loss: 1.30 Accuracy 11.60%\n",
      "Loss: 1.33 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.63%\n",
      "Loss: 1.33 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.71%\n",
      "Loss: 1.35 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.66%\n",
      "Loss: 1.37 Accuracy 11.63%\n",
      "Loss: 1.34 Accuracy 11.64%\n",
      "Loss: 1.32 Accuracy 11.69%\n",
      "Loss: 1.31 Accuracy 11.74%\n",
      "Loss: 1.34 Accuracy 11.72%\n",
      "Loss: 1.34 Accuracy 11.71%\n",
      "Loss: 1.35 Accuracy 11.69%\n",
      "Loss: 1.32 Accuracy 11.71%\n",
      "Loss: 1.36 Accuracy 11.67%\n",
      "Loss: 1.35 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.33 Accuracy 11.69%\n",
      "Loss: 1.33 Accuracy 11.69%\n",
      "Loss: 1.35 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.67%\n",
      "Loss: 1.35 Accuracy 11.66%\n",
      "Loss: 1.34 Accuracy 11.66%\n",
      "Loss: 1.36 Accuracy 11.64%\n",
      "Loss: 1.35 Accuracy 11.65%\n",
      "Loss: 1.32 Accuracy 11.69%\n",
      "Loss: 1.30 Accuracy 11.72%\n",
      "Loss: 1.34 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.70%\n",
      "Loss: 1.37 Accuracy 11.66%\n",
      "Loss: 1.34 Accuracy 11.66%\n",
      "Loss: 1.32 Accuracy 11.68%\n",
      "Loss: 1.35 Accuracy 11.66%\n",
      "Loss: 1.33 Accuracy 11.69%\n",
      "Loss: 1.33 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.71%\n",
      "Loss: 1.32 Accuracy 11.74%\n",
      "Loss: 1.31 Accuracy 11.75%\n",
      "Loss: 1.36 Accuracy 11.72%\n",
      "Loss: 1.36 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.71%\n",
      "Loss: 1.33 Accuracy 11.71%\n",
      "Loss: 1.33 Accuracy 11.71%\n",
      "Loss: 1.33 Accuracy 11.74%\n",
      "Loss: 1.34 Accuracy 11.75%\n",
      "Loss: 1.35 Accuracy 11.74%\n",
      "Loss: 1.34 Accuracy 11.73%\n",
      "Loss: 1.34 Accuracy 11.75%\n",
      "Loss: 1.35 Accuracy 11.74%\n",
      "Loss: 1.33 Accuracy 11.75%\n",
      "Loss: 1.33 Accuracy 11.75%\n",
      "Loss: 1.34 Accuracy 11.76%\n",
      "Loss: 1.32 Accuracy 11.77%\n",
      "Loss: 1.34 Accuracy 11.76%\n",
      "Loss: 1.35 Accuracy 11.75%\n",
      "Loss: 1.36 Accuracy 11.73%\n",
      "Loss: 1.33 Accuracy 11.75%\n",
      "Loss: 1.34 Accuracy 11.74%\n",
      "Loss: 1.32 Accuracy 11.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.30 Accuracy 11.78%\n",
      "Loss: 1.33 Accuracy 11.78%\n",
      "Loss: 1.31 Accuracy 11.81%\n",
      "Loss: 1.34 Accuracy 11.80%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.38 Accuracy 11.76%\n",
      "Loss: 1.36 Accuracy 11.75%\n",
      "Loss: 1.37 Accuracy 11.74%\n",
      "Loss: 1.38 Accuracy 11.71%\n",
      "Loss: 1.34 Accuracy 11.72%\n",
      "Loss: 1.35 Accuracy 11.70%\n",
      "Loss: 1.31 Accuracy 11.73%\n",
      "Loss: 1.34 Accuracy 11.72%\n",
      "Loss: 1.40 Accuracy 11.68%\n",
      "Loss: 1.38 Accuracy 11.67%\n",
      "Loss: 1.38 Accuracy 11.64%\n",
      "Loss: 1.35 Accuracy 11.65%\n",
      "Loss: 1.39 Accuracy 11.62%\n",
      "Loss: 1.34 Accuracy 11.64%\n",
      "Loss: 1.35 Accuracy 11.63%\n",
      "Loss: 1.37 Accuracy 11.60%\n",
      "Loss: 1.35 Accuracy 11.61%\n",
      "Loss: 1.31 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.61%\n",
      "Loss: 1.31 Accuracy 11.64%\n",
      "Loss: 1.32 Accuracy 11.64%\n",
      "Loss: 1.29 Accuracy 11.68%\n",
      "Loss: 1.33 Accuracy 11.68%\n",
      "Loss: 1.32 Accuracy 11.70%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.31 Accuracy 11.71%\n",
      "Loss: 1.35 Accuracy 11.69%\n",
      "Loss: 1.35 Accuracy 11.69%\n",
      "Loss: 1.38 Accuracy 11.66%\n",
      "Loss: 1.34 Accuracy 11.67%\n",
      "Loss: 1.33 Accuracy 11.68%\n",
      "Loss: 1.32 Accuracy 11.68%\n",
      "Loss: 1.33 Accuracy 11.68%\n",
      "Loss: 1.37 Accuracy 11.67%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.38 Accuracy 11.68%\n",
      "Loss: 1.34 Accuracy 11.68%\n",
      "Loss: 1.36 Accuracy 11.67%\n",
      "Loss: 1.34 Accuracy 11.67%\n",
      "Loss: 1.35 Accuracy 11.67%\n",
      "Loss: 1.37 Accuracy 11.65%\n",
      "Loss: 1.37 Accuracy 11.64%\n",
      "Loss: 1.38 Accuracy 11.62%\n",
      "Loss: 1.32 Accuracy 11.63%\n",
      "Loss: 1.31 Accuracy 11.65%\n",
      "Loss: 1.36 Accuracy 11.64%\n",
      "Loss: 1.37 Accuracy 11.62%\n",
      "Loss: 1.35 Accuracy 11.62%\n",
      "Loss: 1.34 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.62%\n",
      "Loss: 1.34 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.62%\n",
      "Loss: 1.34 Accuracy 11.62%\n",
      "Loss: 1.32 Accuracy 11.63%\n",
      "Loss: 1.35 Accuracy 11.62%\n",
      "Loss: 1.35 Accuracy 11.61%\n",
      "Loss: 1.34 Accuracy 11.62%\n",
      "Loss: 1.31 Accuracy 11.64%\n",
      "Loss: 1.33 Accuracy 11.64%\n",
      "Loss: 1.34 Accuracy 11.64%\n",
      "Loss: 1.36 Accuracy 11.63%\n",
      "Loss: 1.36 Accuracy 11.62%\n",
      "Loss: 1.35 Accuracy 11.61%\n",
      "Loss: 1.32 Accuracy 11.63%\n",
      "Loss: 1.34 Accuracy 11.63%\n",
      "Loss: 1.33 Accuracy 11.64%\n",
      "Loss: 1.35 Accuracy 11.64%\n",
      "Loss: 1.31 Accuracy 11.66%\n",
      "Loss: 1.35 Accuracy 11.66%\n",
      "Loss: 1.32 Accuracy 11.67%\n",
      "Loss: 1.33 Accuracy 11.67%\n",
      "Loss: 1.38 Accuracy 11.64%\n",
      "Loss: 1.35 Accuracy 11.65%\n",
      "Loss: 1.37 Accuracy 11.64%\n",
      "Loss: 1.38 Accuracy 11.62%\n",
      "Loss: 1.38 Accuracy 11.61%\n",
      "Loss: 1.37 Accuracy 11.61%\n",
      "Loss: 1.38 Accuracy 11.61%\n",
      "Loss: 1.35 Accuracy 11.60%\n",
      "Loss: 1.38 Accuracy 11.59%\n",
      "Loss: 1.37 Accuracy 11.58%\n",
      "Loss: 1.38 Accuracy 11.57%\n",
      "Loss: 1.39 Accuracy 11.55%\n",
      "Loss: 1.36 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.55%\n",
      "Loss: 1.32 Accuracy 11.56%\n",
      "Loss: 1.34 Accuracy 11.55%\n",
      "Loss: 1.36 Accuracy 11.55%\n",
      "Loss: 1.36 Accuracy 11.54%\n",
      "Loss: 1.37 Accuracy 11.54%\n",
      "Loss: 1.37 Accuracy 11.54%\n",
      "Loss: 1.36 Accuracy 11.53%\n",
      "Loss: 1.32 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.55%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.31 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.31 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.56%\n",
      "Loss: 1.32 Accuracy 11.57%\n",
      "Loss: 1.33 Accuracy 11.58%\n",
      "Loss: 1.33 Accuracy 11.58%\n",
      "Loss: 1.33 Accuracy 11.58%\n",
      "Loss: 1.34 Accuracy 11.58%\n",
      "Loss: 1.33 Accuracy 11.58%\n",
      "Loss: 1.35 Accuracy 11.58%\n",
      "Loss: 1.36 Accuracy 11.57%\n",
      "Loss: 1.35 Accuracy 11.57%\n",
      "Loss: 1.31 Accuracy 11.59%\n",
      "Loss: 1.37 Accuracy 11.57%\n",
      "Loss: 1.34 Accuracy 11.57%\n",
      "Loss: 1.36 Accuracy 11.57%\n",
      "Loss: 1.36 Accuracy 11.57%\n",
      "Loss: 1.36 Accuracy 11.56%\n",
      "Loss: 1.36 Accuracy 11.55%\n",
      "Loss: 1.37 Accuracy 11.55%\n",
      "Loss: 1.34 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.56%\n",
      "Loss: 1.37 Accuracy 11.55%\n",
      "Loss: 1.34 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.56%\n",
      "Loss: 1.35 Accuracy 11.55%\n",
      "Loss: 1.38 Accuracy 11.54%\n",
      "Loss: 1.34 Accuracy 11.55%\n",
      "Loss: 1.39 Accuracy 11.54%\n",
      "Loss: 1.36 Accuracy 11.53%\n",
      "Loss: 1.34 Accuracy 11.54%\n",
      "Loss: 1.33 Accuracy 11.55%\n",
      "Loss: 1.33 Accuracy 11.55%\n",
      "Loss: 1.35 Accuracy 11.54%\n",
      "Loss: 1.36 Accuracy 11.54%\n",
      "Loss: 1.36 Accuracy 11.54%\n",
      "Loss: 1.35 Accuracy 11.54%\n",
      "Loss: 1.37 Accuracy 11.53%\n",
      "Loss: 1.34 Accuracy 11.53%\n",
      "Loss: 1.36 Accuracy 11.53%\n",
      "Loss: 1.37 Accuracy 11.53%\n",
      "Loss: 1.34 Accuracy 11.53%\n",
      "Loss: 1.33 Accuracy 11.54%\n",
      "Loss: 1.35 Accuracy 11.54%\n",
      "Loss: 1.37 Accuracy 11.53%\n",
      "Loss: 1.35 Accuracy 11.53%\n",
      "Loss: 1.34 Accuracy 11.53%\n",
      "Loss: 1.36 Accuracy 11.52%\n",
      "Loss: 1.37 Accuracy 11.52%\n",
      "Loss: 1.38 Accuracy 11.51%\n",
      "Loss: 1.36 Accuracy 11.50%\n",
      "Loss: 1.37 Accuracy 11.50%\n",
      "Loss: 1.35 Accuracy 11.50%\n",
      "Loss: 1.36 Accuracy 11.49%\n",
      "Loss: 1.35 Accuracy 11.49%\n",
      "Loss: 1.35 Accuracy 11.50%\n",
      "Loss: 1.30 Accuracy 11.51%\n",
      "Loss: 1.35 Accuracy 11.50%\n",
      "Loss: 1.34 Accuracy 11.50%\n",
      "Loss: 1.35 Accuracy 11.50%\n",
      "Loss: 1.37 Accuracy 11.50%\n",
      "Loss: 1.36 Accuracy 11.50%\n",
      "Loss: 1.34 Accuracy 11.50%\n",
      "Loss: 1.38 Accuracy 11.49%\n",
      "Loss: 1.35 Accuracy 11.50%\n",
      "Loss: 1.33 Accuracy 11.51%\n",
      "Loss: 1.33 Accuracy 11.51%\n",
      "Loss: 1.37 Accuracy 11.50%\n",
      "Loss: 1.36 Accuracy 11.50%\n",
      "Loss: 1.36 Accuracy 11.50%\n",
      "Loss: 1.37 Accuracy 11.50%\n",
      "Loss: 1.38 Accuracy 11.49%\n",
      "Loss: 1.33 Accuracy 11.50%\n",
      "Test Accuracy: 58.24%\n",
      "Epoch 5\n",
      "Loss: 0.14 Accuracy 9.38%\n",
      "Loss: 0.89 Accuracy 13.07%\n",
      "Loss: 1.17 Accuracy 13.24%\n",
      "Loss: 1.31 Accuracy 11.59%\n",
      "Loss: 1.30 Accuracy 12.20%\n",
      "Loss: 1.35 Accuracy 11.76%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.34 Accuracy 12.15%\n",
      "Loss: 1.36 Accuracy 11.98%\n",
      "Loss: 1.36 Accuracy 11.88%\n",
      "Loss: 1.31 Accuracy 12.16%\n",
      "Loss: 1.35 Accuracy 12.04%\n",
      "Loss: 1.35 Accuracy 11.88%\n",
      "Loss: 1.36 Accuracy 11.66%\n",
      "Loss: 1.37 Accuracy 11.65%\n",
      "Loss: 1.34 Accuracy 11.63%\n",
      "Loss: 1.32 Accuracy 11.73%\n",
      "Loss: 1.36 Accuracy 11.60%\n",
      "Loss: 1.34 Accuracy 11.65%\n",
      "Loss: 1.36 Accuracy 11.58%\n",
      "Loss: 1.34 Accuracy 11.61%\n",
      "Loss: 1.31 Accuracy 11.74%\n",
      "Loss: 1.33 Accuracy 11.73%\n",
      "Loss: 1.30 Accuracy 11.88%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.88%\n",
      "Loss: 1.35 Accuracy 11.81%\n",
      "Loss: 1.31 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.96%\n",
      "Loss: 1.34 Accuracy 11.93%\n",
      "Loss: 1.36 Accuracy 11.86%\n",
      "Loss: 1.32 Accuracy 11.96%\n",
      "Loss: 1.35 Accuracy 11.91%\n",
      "Loss: 1.37 Accuracy 11.83%\n",
      "Loss: 1.36 Accuracy 11.82%\n",
      "Loss: 1.35 Accuracy 11.83%\n",
      "Loss: 1.34 Accuracy 11.83%\n",
      "Loss: 1.33 Accuracy 11.85%\n",
      "Loss: 1.33 Accuracy 11.85%\n",
      "Loss: 1.31 Accuracy 11.90%\n",
      "Loss: 1.32 Accuracy 11.92%\n",
      "Loss: 1.33 Accuracy 11.93%\n",
      "Loss: 1.35 Accuracy 11.88%\n",
      "Loss: 1.36 Accuracy 11.83%\n",
      "Loss: 1.34 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.87%\n",
      "Loss: 1.37 Accuracy 11.79%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.37 Accuracy 11.73%\n",
      "Loss: 1.35 Accuracy 11.74%\n",
      "Loss: 1.31 Accuracy 11.80%\n",
      "Loss: 1.31 Accuracy 11.82%\n",
      "Loss: 1.34 Accuracy 11.81%\n",
      "Loss: 1.33 Accuracy 11.81%\n",
      "Loss: 1.33 Accuracy 11.80%\n",
      "Loss: 1.31 Accuracy 11.85%\n",
      "Loss: 1.31 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.88%\n",
      "Loss: 1.35 Accuracy 11.87%\n",
      "Loss: 1.34 Accuracy 11.87%\n",
      "Loss: 1.31 Accuracy 11.90%\n",
      "Loss: 1.30 Accuracy 11.93%\n",
      "Loss: 1.32 Accuracy 11.94%\n",
      "Loss: 1.34 Accuracy 11.92%\n",
      "Loss: 1.37 Accuracy 11.88%\n",
      "Loss: 1.37 Accuracy 11.86%\n",
      "Loss: 1.34 Accuracy 11.87%\n",
      "Loss: 1.32 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.89%\n",
      "Loss: 1.32 Accuracy 11.90%\n",
      "Loss: 1.34 Accuracy 11.87%\n",
      "Loss: 1.35 Accuracy 11.86%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.36 Accuracy 11.83%\n",
      "Loss: 1.31 Accuracy 11.88%\n",
      "Loss: 1.34 Accuracy 11.86%\n",
      "Loss: 1.36 Accuracy 11.83%\n",
      "Loss: 1.34 Accuracy 11.84%\n",
      "Loss: 1.31 Accuracy 11.87%\n",
      "Loss: 1.34 Accuracy 11.86%\n",
      "Loss: 1.34 Accuracy 11.85%\n",
      "Loss: 1.32 Accuracy 11.86%\n",
      "Loss: 1.31 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.89%\n",
      "Loss: 1.32 Accuracy 11.90%\n",
      "Loss: 1.33 Accuracy 11.89%\n",
      "Loss: 1.31 Accuracy 11.90%\n",
      "Loss: 1.34 Accuracy 11.89%\n",
      "Loss: 1.33 Accuracy 11.91%\n",
      "Loss: 1.33 Accuracy 11.91%\n",
      "Loss: 1.35 Accuracy 11.88%\n",
      "Loss: 1.34 Accuracy 11.88%\n",
      "Loss: 1.30 Accuracy 11.90%\n",
      "Loss: 1.31 Accuracy 11.90%\n",
      "Loss: 1.31 Accuracy 11.91%\n",
      "Loss: 1.32 Accuracy 11.93%\n",
      "Loss: 1.31 Accuracy 11.95%\n",
      "Loss: 1.32 Accuracy 11.95%\n",
      "Loss: 1.28 Accuracy 11.99%\n",
      "Loss: 1.29 Accuracy 12.01%\n",
      "Loss: 1.32 Accuracy 12.01%\n",
      "Loss: 1.34 Accuracy 12.01%\n",
      "Loss: 1.32 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.03%\n",
      "Loss: 1.33 Accuracy 12.03%\n",
      "Loss: 1.35 Accuracy 12.01%\n",
      "Loss: 1.31 Accuracy 12.03%\n",
      "Loss: 1.34 Accuracy 12.02%\n",
      "Loss: 1.35 Accuracy 12.02%\n",
      "Loss: 1.34 Accuracy 12.02%\n",
      "Loss: 1.36 Accuracy 12.00%\n",
      "Loss: 1.36 Accuracy 11.99%\n",
      "Loss: 1.34 Accuracy 11.99%\n",
      "Loss: 1.34 Accuracy 11.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.29 Accuracy 12.02%\n",
      "Loss: 1.31 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.02%\n",
      "Loss: 1.32 Accuracy 12.04%\n",
      "Loss: 1.32 Accuracy 12.03%\n",
      "Loss: 1.37 Accuracy 12.00%\n",
      "Loss: 1.33 Accuracy 12.01%\n",
      "Loss: 1.34 Accuracy 12.00%\n",
      "Loss: 1.33 Accuracy 11.99%\n",
      "Loss: 1.36 Accuracy 11.99%\n",
      "Loss: 1.35 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 12.00%\n",
      "Loss: 1.33 Accuracy 11.99%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.99%\n",
      "Loss: 1.30 Accuracy 12.01%\n",
      "Loss: 1.32 Accuracy 12.01%\n",
      "Loss: 1.36 Accuracy 11.99%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.33 Accuracy 12.00%\n",
      "Loss: 1.36 Accuracy 11.99%\n",
      "Loss: 1.35 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.01%\n",
      "Loss: 1.36 Accuracy 11.99%\n",
      "Loss: 1.34 Accuracy 11.99%\n",
      "Loss: 1.36 Accuracy 11.96%\n",
      "Loss: 1.31 Accuracy 11.98%\n",
      "Loss: 1.36 Accuracy 11.96%\n",
      "Loss: 1.34 Accuracy 11.96%\n",
      "Loss: 1.36 Accuracy 11.94%\n",
      "Loss: 1.30 Accuracy 11.96%\n",
      "Loss: 1.31 Accuracy 11.97%\n",
      "Loss: 1.33 Accuracy 11.97%\n",
      "Loss: 1.34 Accuracy 11.95%\n",
      "Loss: 1.34 Accuracy 11.94%\n",
      "Loss: 1.34 Accuracy 11.94%\n",
      "Loss: 1.34 Accuracy 11.94%\n",
      "Loss: 1.30 Accuracy 11.95%\n",
      "Loss: 1.29 Accuracy 11.97%\n",
      "Loss: 1.34 Accuracy 11.97%\n",
      "Loss: 1.32 Accuracy 11.97%\n",
      "Loss: 1.36 Accuracy 11.95%\n",
      "Loss: 1.33 Accuracy 11.95%\n",
      "Loss: 1.34 Accuracy 11.96%\n",
      "Loss: 1.33 Accuracy 11.95%\n",
      "Loss: 1.32 Accuracy 11.96%\n",
      "Loss: 1.34 Accuracy 11.95%\n",
      "Loss: 1.33 Accuracy 11.95%\n",
      "Loss: 1.35 Accuracy 11.94%\n",
      "Loss: 1.37 Accuracy 11.93%\n",
      "Loss: 1.33 Accuracy 11.94%\n",
      "Loss: 1.35 Accuracy 11.94%\n",
      "Loss: 1.35 Accuracy 11.93%\n",
      "Loss: 1.34 Accuracy 11.93%\n",
      "Loss: 1.37 Accuracy 11.91%\n",
      "Loss: 1.34 Accuracy 11.91%\n",
      "Loss: 1.32 Accuracy 11.92%\n",
      "Loss: 1.35 Accuracy 11.90%\n",
      "Loss: 1.36 Accuracy 11.89%\n",
      "Loss: 1.36 Accuracy 11.88%\n",
      "Loss: 1.35 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.89%\n",
      "Loss: 1.32 Accuracy 11.89%\n",
      "Loss: 1.37 Accuracy 11.87%\n",
      "Loss: 1.33 Accuracy 11.87%\n",
      "Loss: 1.31 Accuracy 11.88%\n",
      "Loss: 1.34 Accuracy 11.88%\n",
      "Loss: 1.37 Accuracy 11.86%\n",
      "Loss: 1.37 Accuracy 11.85%\n",
      "Loss: 1.34 Accuracy 11.86%\n",
      "Loss: 1.32 Accuracy 11.86%\n",
      "Loss: 1.32 Accuracy 11.87%\n",
      "Loss: 1.31 Accuracy 11.89%\n",
      "Loss: 1.34 Accuracy 11.88%\n",
      "Loss: 1.32 Accuracy 11.88%\n",
      "Loss: 1.33 Accuracy 11.88%\n",
      "Loss: 1.31 Accuracy 11.89%\n",
      "Loss: 1.33 Accuracy 11.88%\n",
      "Loss: 1.34 Accuracy 11.88%\n",
      "Loss: 1.38 Accuracy 11.86%\n",
      "Loss: 1.31 Accuracy 11.87%\n",
      "Loss: 1.34 Accuracy 11.87%\n",
      "Loss: 1.35 Accuracy 11.86%\n",
      "Loss: 1.34 Accuracy 11.86%\n",
      "Loss: 1.34 Accuracy 11.86%\n",
      "Loss: 1.35 Accuracy 11.85%\n",
      "Loss: 1.38 Accuracy 11.84%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.37 Accuracy 11.82%\n",
      "Loss: 1.33 Accuracy 11.83%\n",
      "Loss: 1.33 Accuracy 11.83%\n",
      "Loss: 1.32 Accuracy 11.83%\n",
      "Loss: 1.30 Accuracy 11.85%\n",
      "Loss: 1.32 Accuracy 11.85%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.84%\n",
      "Loss: 1.32 Accuracy 11.85%\n",
      "Loss: 1.31 Accuracy 11.86%\n",
      "Loss: 1.35 Accuracy 11.85%\n",
      "Loss: 1.34 Accuracy 11.85%\n",
      "Loss: 1.32 Accuracy 11.86%\n",
      "Loss: 1.35 Accuracy 11.85%\n",
      "Loss: 1.31 Accuracy 11.86%\n",
      "Loss: 1.36 Accuracy 11.85%\n",
      "Loss: 1.39 Accuracy 11.83%\n",
      "Loss: 1.32 Accuracy 11.85%\n",
      "Loss: 1.37 Accuracy 11.83%\n",
      "Loss: 1.35 Accuracy 11.82%\n",
      "Loss: 1.33 Accuracy 11.83%\n",
      "Loss: 1.34 Accuracy 11.83%\n",
      "Loss: 1.32 Accuracy 11.83%\n",
      "Loss: 1.35 Accuracy 11.82%\n",
      "Loss: 1.35 Accuracy 11.82%\n",
      "Loss: 1.34 Accuracy 11.82%\n",
      "Loss: 1.30 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.83%\n",
      "Loss: 1.30 Accuracy 11.84%\n",
      "Loss: 1.31 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.84%\n",
      "Loss: 1.33 Accuracy 11.84%\n",
      "Loss: 1.32 Accuracy 11.85%\n",
      "Loss: 1.30 Accuracy 11.85%\n",
      "Loss: 1.34 Accuracy 11.85%\n",
      "Loss: 1.32 Accuracy 11.86%\n",
      "Loss: 1.36 Accuracy 11.84%\n",
      "Loss: 1.37 Accuracy 11.83%\n",
      "Loss: 1.36 Accuracy 11.83%\n",
      "Loss: 1.35 Accuracy 11.83%\n",
      "Loss: 1.36 Accuracy 11.83%\n",
      "Loss: 1.35 Accuracy 11.83%\n",
      "Loss: 1.33 Accuracy 11.83%\n",
      "Loss: 1.31 Accuracy 11.84%\n",
      "Loss: 1.32 Accuracy 11.84%\n",
      "Loss: 1.31 Accuracy 11.85%\n",
      "Loss: 1.34 Accuracy 11.85%\n",
      "Loss: 1.35 Accuracy 11.84%\n",
      "Loss: 1.38 Accuracy 11.83%\n",
      "Loss: 1.34 Accuracy 11.83%\n",
      "Loss: 1.36 Accuracy 11.82%\n",
      "Loss: 1.36 Accuracy 11.81%\n",
      "Loss: 1.33 Accuracy 11.82%\n",
      "Loss: 1.34 Accuracy 11.81%\n",
      "Loss: 1.31 Accuracy 11.82%\n",
      "Loss: 1.32 Accuracy 11.82%\n",
      "Loss: 1.33 Accuracy 11.82%\n",
      "Loss: 1.35 Accuracy 11.82%\n",
      "Loss: 1.34 Accuracy 11.82%\n",
      "Loss: 1.34 Accuracy 11.83%\n",
      "Loss: 1.37 Accuracy 11.81%\n",
      "Loss: 1.39 Accuracy 11.80%\n",
      "Loss: 1.37 Accuracy 11.79%\n",
      "Loss: 1.32 Accuracy 11.80%\n",
      "Loss: 1.34 Accuracy 11.80%\n",
      "Loss: 1.33 Accuracy 11.80%\n",
      "Loss: 1.37 Accuracy 11.80%\n",
      "Loss: 1.37 Accuracy 11.79%\n",
      "Loss: 1.35 Accuracy 11.79%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.36 Accuracy 11.79%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.32 Accuracy 11.80%\n",
      "Loss: 1.34 Accuracy 11.79%\n",
      "Loss: 1.37 Accuracy 11.79%\n",
      "Test Accuracy: 57.40%\n",
      "Epoch 6\n",
      "Loss: 0.13 Accuracy 15.62%\n",
      "Loss: 0.91 Accuracy 11.65%\n",
      "Loss: 1.18 Accuracy 12.35%\n",
      "Loss: 1.27 Accuracy 12.40%\n",
      "Loss: 1.30 Accuracy 12.50%\n",
      "Loss: 1.29 Accuracy 13.05%\n",
      "Loss: 1.31 Accuracy 12.86%\n",
      "Loss: 1.32 Accuracy 12.76%\n",
      "Loss: 1.33 Accuracy 12.77%\n",
      "Loss: 1.35 Accuracy 12.36%\n",
      "Loss: 1.35 Accuracy 12.10%\n",
      "Loss: 1.36 Accuracy 11.97%\n",
      "Loss: 1.30 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.33%\n",
      "Loss: 1.32 Accuracy 12.32%\n",
      "Loss: 1.30 Accuracy 12.48%\n",
      "Loss: 1.30 Accuracy 12.50%\n",
      "Loss: 1.31 Accuracy 12.50%\n",
      "Loss: 1.31 Accuracy 12.53%\n",
      "Loss: 1.32 Accuracy 12.55%\n",
      "Loss: 1.30 Accuracy 12.61%\n",
      "Loss: 1.34 Accuracy 12.49%\n",
      "Loss: 1.32 Accuracy 12.51%\n",
      "Loss: 1.34 Accuracy 12.45%\n",
      "Loss: 1.32 Accuracy 12.41%\n",
      "Loss: 1.32 Accuracy 12.45%\n",
      "Loss: 1.35 Accuracy 12.33%\n",
      "Loss: 1.33 Accuracy 12.36%\n",
      "Loss: 1.32 Accuracy 12.40%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.35 Accuracy 12.15%\n",
      "Loss: 1.34 Accuracy 12.16%\n",
      "Loss: 1.28 Accuracy 12.25%\n",
      "Loss: 1.30 Accuracy 12.29%\n",
      "Loss: 1.32 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.32%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.35 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.32%\n",
      "Loss: 1.29 Accuracy 12.36%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.35%\n",
      "Loss: 1.31 Accuracy 12.38%\n",
      "Loss: 1.34 Accuracy 12.33%\n",
      "Loss: 1.31 Accuracy 12.37%\n",
      "Loss: 1.32 Accuracy 12.38%\n",
      "Loss: 1.34 Accuracy 12.36%\n",
      "Loss: 1.36 Accuracy 12.31%\n",
      "Loss: 1.33 Accuracy 12.33%\n",
      "Loss: 1.35 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.35 Accuracy 12.17%\n",
      "Loss: 1.29 Accuracy 12.23%\n",
      "Loss: 1.36 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.17%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.33 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.33 Accuracy 12.20%\n",
      "Loss: 1.36 Accuracy 12.18%\n",
      "Loss: 1.35 Accuracy 12.16%\n",
      "Loss: 1.32 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.17%\n",
      "Loss: 1.30 Accuracy 12.19%\n",
      "Loss: 1.36 Accuracy 12.16%\n",
      "Loss: 1.36 Accuracy 12.13%\n",
      "Loss: 1.36 Accuracy 12.11%\n",
      "Loss: 1.33 Accuracy 12.11%\n",
      "Loss: 1.29 Accuracy 12.16%\n",
      "Loss: 1.31 Accuracy 12.16%\n",
      "Loss: 1.29 Accuracy 12.18%\n",
      "Loss: 1.29 Accuracy 12.20%\n",
      "Loss: 1.33 Accuracy 12.18%\n",
      "Loss: 1.28 Accuracy 12.22%\n",
      "Loss: 1.29 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.36 Accuracy 12.21%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.36 Accuracy 12.22%\n",
      "Loss: 1.37 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.36 Accuracy 12.18%\n",
      "Loss: 1.36 Accuracy 12.16%\n",
      "Loss: 1.37 Accuracy 12.13%\n",
      "Loss: 1.38 Accuracy 12.11%\n",
      "Loss: 1.37 Accuracy 12.08%\n",
      "Loss: 1.31 Accuracy 12.10%\n",
      "Loss: 1.30 Accuracy 12.13%\n",
      "Loss: 1.31 Accuracy 12.14%\n",
      "Loss: 1.35 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.33 Accuracy 12.09%\n",
      "Loss: 1.35 Accuracy 12.07%\n",
      "Loss: 1.36 Accuracy 12.04%\n",
      "Loss: 1.34 Accuracy 12.05%\n",
      "Loss: 1.31 Accuracy 12.07%\n",
      "Loss: 1.33 Accuracy 12.07%\n",
      "Loss: 1.31 Accuracy 12.08%\n",
      "Loss: 1.31 Accuracy 12.09%\n",
      "Loss: 1.31 Accuracy 12.10%\n",
      "Loss: 1.28 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.11%\n",
      "Loss: 1.36 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.10%\n",
      "Loss: 1.35 Accuracy 12.08%\n",
      "Loss: 1.33 Accuracy 12.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.29 Accuracy 12.11%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.35 Accuracy 12.08%\n",
      "Loss: 1.39 Accuracy 12.05%\n",
      "Loss: 1.34 Accuracy 12.04%\n",
      "Loss: 1.32 Accuracy 12.05%\n",
      "Loss: 1.34 Accuracy 12.04%\n",
      "Loss: 1.36 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.03%\n",
      "Loss: 1.33 Accuracy 12.03%\n",
      "Loss: 1.31 Accuracy 12.04%\n",
      "Loss: 1.35 Accuracy 12.02%\n",
      "Loss: 1.34 Accuracy 12.01%\n",
      "Loss: 1.33 Accuracy 12.01%\n",
      "Loss: 1.31 Accuracy 12.02%\n",
      "Loss: 1.34 Accuracy 12.01%\n",
      "Loss: 1.35 Accuracy 12.01%\n",
      "Loss: 1.31 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.04%\n",
      "Loss: 1.32 Accuracy 12.04%\n",
      "Loss: 1.31 Accuracy 12.05%\n",
      "Loss: 1.31 Accuracy 12.06%\n",
      "Loss: 1.29 Accuracy 12.08%\n",
      "Loss: 1.32 Accuracy 12.08%\n",
      "Loss: 1.33 Accuracy 12.07%\n",
      "Loss: 1.32 Accuracy 12.08%\n",
      "Loss: 1.37 Accuracy 12.06%\n",
      "Loss: 1.35 Accuracy 12.05%\n",
      "Loss: 1.34 Accuracy 12.06%\n",
      "Loss: 1.32 Accuracy 12.06%\n",
      "Loss: 1.34 Accuracy 12.05%\n",
      "Loss: 1.34 Accuracy 12.05%\n",
      "Loss: 1.36 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.05%\n",
      "Loss: 1.31 Accuracy 12.06%\n",
      "Loss: 1.34 Accuracy 12.06%\n",
      "Loss: 1.35 Accuracy 12.04%\n",
      "Loss: 1.37 Accuracy 12.03%\n",
      "Loss: 1.35 Accuracy 12.04%\n",
      "Loss: 1.32 Accuracy 12.04%\n",
      "Loss: 1.32 Accuracy 12.05%\n",
      "Loss: 1.32 Accuracy 12.05%\n",
      "Loss: 1.38 Accuracy 12.03%\n",
      "Loss: 1.35 Accuracy 12.03%\n",
      "Loss: 1.33 Accuracy 12.03%\n",
      "Loss: 1.33 Accuracy 12.03%\n",
      "Loss: 1.32 Accuracy 12.04%\n",
      "Loss: 1.30 Accuracy 12.05%\n",
      "Loss: 1.34 Accuracy 12.03%\n",
      "Loss: 1.34 Accuracy 12.03%\n",
      "Loss: 1.35 Accuracy 12.03%\n",
      "Loss: 1.38 Accuracy 12.01%\n",
      "Loss: 1.37 Accuracy 12.00%\n",
      "Loss: 1.33 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 11.99%\n",
      "Loss: 1.36 Accuracy 11.98%\n",
      "Loss: 1.29 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.38 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.99%\n",
      "Loss: 1.30 Accuracy 12.01%\n",
      "Loss: 1.31 Accuracy 12.01%\n",
      "Loss: 1.35 Accuracy 12.00%\n",
      "Loss: 1.34 Accuracy 12.00%\n",
      "Loss: 1.34 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 11.99%\n",
      "Loss: 1.37 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.36 Accuracy 11.97%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.36 Accuracy 11.96%\n",
      "Loss: 1.39 Accuracy 11.94%\n",
      "Loss: 1.34 Accuracy 11.95%\n",
      "Loss: 1.35 Accuracy 11.95%\n",
      "Loss: 1.36 Accuracy 11.94%\n",
      "Loss: 1.31 Accuracy 11.95%\n",
      "Loss: 1.31 Accuracy 11.95%\n",
      "Loss: 1.33 Accuracy 11.95%\n",
      "Loss: 1.32 Accuracy 11.96%\n",
      "Loss: 1.33 Accuracy 11.95%\n",
      "Loss: 1.35 Accuracy 11.94%\n",
      "Loss: 1.33 Accuracy 11.96%\n",
      "Loss: 1.35 Accuracy 11.95%\n",
      "Loss: 1.35 Accuracy 11.95%\n",
      "Loss: 1.36 Accuracy 11.94%\n",
      "Loss: 1.36 Accuracy 11.93%\n",
      "Loss: 1.32 Accuracy 11.93%\n",
      "Loss: 1.33 Accuracy 11.94%\n",
      "Loss: 1.32 Accuracy 11.94%\n",
      "Loss: 1.33 Accuracy 11.94%\n",
      "Loss: 1.34 Accuracy 11.93%\n",
      "Loss: 1.32 Accuracy 11.94%\n",
      "Loss: 1.27 Accuracy 11.96%\n",
      "Loss: 1.27 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.98%\n",
      "Loss: 1.30 Accuracy 11.99%\n",
      "Loss: 1.31 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.34 Accuracy 11.99%\n",
      "Loss: 1.35 Accuracy 11.98%\n",
      "Loss: 1.35 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.99%\n",
      "Loss: 1.35 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.99%\n",
      "Loss: 1.35 Accuracy 11.99%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.35 Accuracy 11.97%\n",
      "Loss: 1.34 Accuracy 11.97%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.30 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 11.99%\n",
      "Loss: 1.30 Accuracy 12.00%\n",
      "Loss: 1.35 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.37 Accuracy 11.98%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.34 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.30 Accuracy 11.99%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.32 Accuracy 11.98%\n",
      "Loss: 1.33 Accuracy 11.98%\n",
      "Loss: 1.31 Accuracy 11.98%\n",
      "Loss: 1.29 Accuracy 11.99%\n",
      "Loss: 1.29 Accuracy 12.00%\n",
      "Loss: 1.30 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 12.01%\n",
      "Test Accuracy: 59.29%\n",
      "Epoch 7\n",
      "Loss: 0.14 Accuracy 9.38%\n",
      "Loss: 0.90 Accuracy 13.35%\n",
      "Loss: 1.17 Accuracy 12.95%\n",
      "Loss: 1.26 Accuracy 12.80%\n",
      "Loss: 1.32 Accuracy 12.42%\n",
      "Loss: 1.34 Accuracy 12.01%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.34 Accuracy 11.84%\n",
      "Loss: 1.36 Accuracy 11.61%\n",
      "Loss: 1.32 Accuracy 11.85%\n",
      "Loss: 1.31 Accuracy 11.94%\n",
      "Loss: 1.31 Accuracy 12.11%\n",
      "Loss: 1.36 Accuracy 11.78%\n",
      "Loss: 1.31 Accuracy 12.00%\n",
      "Loss: 1.32 Accuracy 11.99%\n",
      "Loss: 1.32 Accuracy 12.00%\n",
      "Loss: 1.29 Accuracy 12.21%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.14%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.29 Accuracy 12.34%\n",
      "Loss: 1.34 Accuracy 12.32%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.31 Accuracy 12.29%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.34%\n",
      "Loss: 1.34 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.33%\n",
      "Loss: 1.36 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.34 Accuracy 12.16%\n",
      "Loss: 1.34 Accuracy 12.16%\n",
      "Loss: 1.33 Accuracy 12.15%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.33 Accuracy 12.18%\n",
      "Loss: 1.36 Accuracy 12.10%\n",
      "Loss: 1.31 Accuracy 12.17%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.15%\n",
      "Loss: 1.33 Accuracy 12.15%\n",
      "Loss: 1.28 Accuracy 12.24%\n",
      "Loss: 1.29 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.35 Accuracy 12.25%\n",
      "Loss: 1.36 Accuracy 12.19%\n",
      "Loss: 1.40 Accuracy 12.11%\n",
      "Loss: 1.39 Accuracy 12.05%\n",
      "Loss: 1.32 Accuracy 12.08%\n",
      "Loss: 1.32 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.29 Accuracy 12.17%\n",
      "Loss: 1.30 Accuracy 12.20%\n",
      "Loss: 1.27 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.30 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.27%\n",
      "Loss: 1.30 Accuracy 12.28%\n",
      "Loss: 1.31 Accuracy 12.30%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.28 Accuracy 12.32%\n",
      "Loss: 1.30 Accuracy 12.32%\n",
      "Loss: 1.35 Accuracy 12.27%\n",
      "Loss: 1.36 Accuracy 12.24%\n",
      "Loss: 1.34 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.22%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.25%\n",
      "Loss: 1.26 Accuracy 12.29%\n",
      "Loss: 1.32 Accuracy 12.29%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.36 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.26%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.30 Accuracy 12.29%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.36 Accuracy 12.24%\n",
      "Loss: 1.38 Accuracy 12.21%\n",
      "Loss: 1.36 Accuracy 12.20%\n",
      "Loss: 1.31 Accuracy 12.22%\n",
      "Loss: 1.33 Accuracy 12.21%\n",
      "Loss: 1.35 Accuracy 12.20%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.30 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.34 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.20%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.18%\n",
      "Loss: 1.36 Accuracy 12.16%\n",
      "Loss: 1.37 Accuracy 12.13%\n",
      "Loss: 1.36 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.11%\n",
      "Loss: 1.31 Accuracy 12.13%\n",
      "Loss: 1.31 Accuracy 12.14%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.14%\n",
      "Loss: 1.29 Accuracy 12.16%\n",
      "Loss: 1.29 Accuracy 12.17%\n",
      "Loss: 1.29 Accuracy 12.19%\n",
      "Loss: 1.28 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.31 Accuracy 12.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.31 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.30 Accuracy 12.21%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.36 Accuracy 12.19%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.17%\n",
      "Loss: 1.36 Accuracy 12.17%\n",
      "Loss: 1.34 Accuracy 12.17%\n",
      "Loss: 1.33 Accuracy 12.17%\n",
      "Loss: 1.32 Accuracy 12.17%\n",
      "Loss: 1.30 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.17%\n",
      "Loss: 1.30 Accuracy 12.18%\n",
      "Loss: 1.31 Accuracy 12.18%\n",
      "Loss: 1.28 Accuracy 12.20%\n",
      "Loss: 1.30 Accuracy 12.20%\n",
      "Loss: 1.30 Accuracy 12.21%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.33 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.36 Accuracy 12.18%\n",
      "Loss: 1.36 Accuracy 12.16%\n",
      "Loss: 1.34 Accuracy 12.16%\n",
      "Loss: 1.32 Accuracy 12.16%\n",
      "Loss: 1.30 Accuracy 12.17%\n",
      "Loss: 1.33 Accuracy 12.16%\n",
      "Loss: 1.35 Accuracy 12.15%\n",
      "Loss: 1.35 Accuracy 12.14%\n",
      "Loss: 1.33 Accuracy 12.15%\n",
      "Loss: 1.31 Accuracy 12.15%\n",
      "Loss: 1.36 Accuracy 12.13%\n",
      "Loss: 1.37 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.30 Accuracy 12.13%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.35 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.38 Accuracy 12.08%\n",
      "Loss: 1.35 Accuracy 12.07%\n",
      "Loss: 1.32 Accuracy 12.08%\n",
      "Loss: 1.28 Accuracy 12.11%\n",
      "Loss: 1.31 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.31 Accuracy 12.11%\n",
      "Loss: 1.31 Accuracy 12.11%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.13%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.37 Accuracy 12.11%\n",
      "Loss: 1.36 Accuracy 12.10%\n",
      "Loss: 1.35 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.34 Accuracy 12.08%\n",
      "Loss: 1.34 Accuracy 12.08%\n",
      "Loss: 1.30 Accuracy 12.10%\n",
      "Loss: 1.31 Accuracy 12.09%\n",
      "Loss: 1.35 Accuracy 12.08%\n",
      "Loss: 1.32 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.09%\n",
      "Loss: 1.32 Accuracy 12.10%\n",
      "Loss: 1.28 Accuracy 12.11%\n",
      "Loss: 1.29 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.12%\n",
      "Loss: 1.37 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.10%\n",
      "Loss: 1.31 Accuracy 12.10%\n",
      "Loss: 1.35 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.10%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Loss: 1.31 Accuracy 12.11%\n",
      "Loss: 1.33 Accuracy 12.11%\n",
      "Loss: 1.37 Accuracy 12.09%\n",
      "Loss: 1.35 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.09%\n",
      "Loss: 1.35 Accuracy 12.08%\n",
      "Loss: 1.35 Accuracy 12.07%\n",
      "Loss: 1.35 Accuracy 12.07%\n",
      "Loss: 1.36 Accuracy 12.06%\n",
      "Loss: 1.34 Accuracy 12.06%\n",
      "Loss: 1.33 Accuracy 12.06%\n",
      "Loss: 1.31 Accuracy 12.06%\n",
      "Loss: 1.29 Accuracy 12.07%\n",
      "Loss: 1.30 Accuracy 12.08%\n",
      "Loss: 1.32 Accuracy 12.08%\n",
      "Loss: 1.31 Accuracy 12.08%\n",
      "Loss: 1.34 Accuracy 12.07%\n",
      "Loss: 1.35 Accuracy 12.07%\n",
      "Loss: 1.34 Accuracy 12.06%\n",
      "Loss: 1.29 Accuracy 12.08%\n",
      "Loss: 1.30 Accuracy 12.08%\n",
      "Loss: 1.30 Accuracy 12.09%\n",
      "Loss: 1.34 Accuracy 12.08%\n",
      "Loss: 1.33 Accuracy 12.08%\n",
      "Loss: 1.33 Accuracy 12.08%\n",
      "Loss: 1.30 Accuracy 12.09%\n",
      "Loss: 1.31 Accuracy 12.09%\n",
      "Loss: 1.32 Accuracy 12.09%\n",
      "Loss: 1.33 Accuracy 12.09%\n",
      "Loss: 1.31 Accuracy 12.10%\n",
      "Loss: 1.34 Accuracy 12.09%\n",
      "Loss: 1.37 Accuracy 12.08%\n",
      "Test Accuracy: 59.67%\n",
      "Epoch 8\n",
      "Loss: 0.13 Accuracy 15.62%\n",
      "Loss: 0.93 Accuracy 9.38%\n",
      "Loss: 1.16 Accuracy 12.35%\n",
      "Loss: 1.30 Accuracy 11.29%\n",
      "Loss: 1.33 Accuracy 11.43%\n",
      "Loss: 1.32 Accuracy 11.64%\n",
      "Loss: 1.32 Accuracy 11.94%\n",
      "Loss: 1.35 Accuracy 11.53%\n",
      "Loss: 1.32 Accuracy 11.65%\n",
      "Loss: 1.32 Accuracy 11.78%\n",
      "Loss: 1.36 Accuracy 11.54%\n",
      "Loss: 1.34 Accuracy 11.54%\n",
      "Loss: 1.32 Accuracy 11.67%\n",
      "Loss: 1.32 Accuracy 11.74%\n",
      "Loss: 1.31 Accuracy 11.77%\n",
      "Loss: 1.32 Accuracy 11.82%\n",
      "Loss: 1.35 Accuracy 11.70%\n",
      "Loss: 1.29 Accuracy 11.97%\n",
      "Loss: 1.30 Accuracy 12.03%\n",
      "Loss: 1.31 Accuracy 12.06%\n",
      "Loss: 1.33 Accuracy 11.97%\n",
      "Loss: 1.33 Accuracy 11.91%\n",
      "Loss: 1.34 Accuracy 11.84%\n",
      "Loss: 1.29 Accuracy 11.97%\n",
      "Loss: 1.30 Accuracy 11.98%\n",
      "Loss: 1.27 Accuracy 12.15%\n",
      "Loss: 1.28 Accuracy 12.24%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.30 Accuracy 12.30%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.31 Accuracy 12.29%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.29 Accuracy 12.30%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.31%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.30 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.31%\n",
      "Loss: 1.29 Accuracy 12.35%\n",
      "Loss: 1.31 Accuracy 12.37%\n",
      "Loss: 1.32 Accuracy 12.35%\n",
      "Loss: 1.32 Accuracy 12.36%\n",
      "Loss: 1.33 Accuracy 12.32%\n",
      "Loss: 1.36 Accuracy 12.27%\n",
      "Loss: 1.30 Accuracy 12.32%\n",
      "Loss: 1.29 Accuracy 12.36%\n",
      "Loss: 1.32 Accuracy 12.34%\n",
      "Loss: 1.32 Accuracy 12.36%\n",
      "Loss: 1.32 Accuracy 12.37%\n",
      "Loss: 1.29 Accuracy 12.40%\n",
      "Loss: 1.31 Accuracy 12.40%\n",
      "Loss: 1.34 Accuracy 12.40%\n",
      "Loss: 1.32 Accuracy 12.41%\n",
      "Loss: 1.32 Accuracy 12.38%\n",
      "Loss: 1.32 Accuracy 12.36%\n",
      "Loss: 1.31 Accuracy 12.36%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.33%\n",
      "Loss: 1.32 Accuracy 12.32%\n",
      "Loss: 1.32 Accuracy 12.31%\n",
      "Loss: 1.30 Accuracy 12.35%\n",
      "Loss: 1.28 Accuracy 12.39%\n",
      "Loss: 1.30 Accuracy 12.39%\n",
      "Loss: 1.29 Accuracy 12.41%\n",
      "Loss: 1.31 Accuracy 12.41%\n",
      "Loss: 1.27 Accuracy 12.45%\n",
      "Loss: 1.33 Accuracy 12.41%\n",
      "Loss: 1.34 Accuracy 12.39%\n",
      "Loss: 1.34 Accuracy 12.38%\n",
      "Loss: 1.33 Accuracy 12.37%\n",
      "Loss: 1.30 Accuracy 12.38%\n",
      "Loss: 1.35 Accuracy 12.35%\n",
      "Loss: 1.36 Accuracy 12.32%\n",
      "Loss: 1.34 Accuracy 12.31%\n",
      "Loss: 1.35 Accuracy 12.29%\n",
      "Loss: 1.37 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.33 Accuracy 12.22%\n",
      "Loss: 1.36 Accuracy 12.20%\n",
      "Loss: 1.34 Accuracy 12.20%\n",
      "Loss: 1.31 Accuracy 12.21%\n",
      "Loss: 1.30 Accuracy 12.23%\n",
      "Loss: 1.34 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.29 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.29 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.34 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.26%\n",
      "Loss: 1.30 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.26%\n",
      "Loss: 1.32 Accuracy 12.26%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.35 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.23%\n",
      "Loss: 1.34 Accuracy 12.22%\n",
      "Loss: 1.28 Accuracy 12.25%\n",
      "Loss: 1.30 Accuracy 12.26%\n",
      "Loss: 1.30 Accuracy 12.26%\n",
      "Loss: 1.29 Accuracy 12.28%\n",
      "Loss: 1.34 Accuracy 12.26%\n",
      "Loss: 1.30 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.26%\n",
      "Loss: 1.32 Accuracy 12.27%\n",
      "Loss: 1.30 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.34 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.29 Accuracy 12.29%\n",
      "Loss: 1.32 Accuracy 12.29%\n",
      "Loss: 1.35 Accuracy 12.27%\n",
      "Loss: 1.35 Accuracy 12.26%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.36 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.22%\n",
      "Loss: 1.35 Accuracy 12.21%\n",
      "Loss: 1.35 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.31 Accuracy 12.22%\n",
      "Loss: 1.30 Accuracy 12.23%\n",
      "Loss: 1.29 Accuracy 12.25%\n",
      "Loss: 1.23 Accuracy 12.30%\n",
      "Loss: 1.31 Accuracy 12.29%\n",
      "Loss: 1.37 Accuracy 12.27%\n",
      "Loss: 1.38 Accuracy 12.26%\n",
      "Loss: 1.36 Accuracy 12.25%\n",
      "Loss: 1.35 Accuracy 12.25%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.34 Accuracy 12.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.35 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.35 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.28 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.23%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.36 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.23%\n",
      "Loss: 1.37 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.33 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.33 Accuracy 12.22%\n",
      "Loss: 1.36 Accuracy 12.20%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.27 Accuracy 12.24%\n",
      "Loss: 1.30 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.29 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.23%\n",
      "Loss: 1.36 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.35 Accuracy 12.21%\n",
      "Loss: 1.30 Accuracy 12.22%\n",
      "Loss: 1.29 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.23%\n",
      "Loss: 1.35 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.23%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.33 Accuracy 12.21%\n",
      "Loss: 1.32 Accuracy 12.21%\n",
      "Loss: 1.33 Accuracy 12.21%\n",
      "Loss: 1.35 Accuracy 12.20%\n",
      "Loss: 1.37 Accuracy 12.19%\n",
      "Loss: 1.36 Accuracy 12.18%\n",
      "Loss: 1.32 Accuracy 12.18%\n",
      "Loss: 1.29 Accuracy 12.20%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.34 Accuracy 12.18%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.38 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.20%\n",
      "Loss: 1.35 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.18%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.20%\n",
      "Loss: 1.31 Accuracy 12.20%\n",
      "Loss: 1.36 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.17%\n",
      "Loss: 1.35 Accuracy 12.16%\n",
      "Loss: 1.34 Accuracy 12.16%\n",
      "Loss: 1.32 Accuracy 12.16%\n",
      "Loss: 1.34 Accuracy 12.15%\n",
      "Loss: 1.33 Accuracy 12.15%\n",
      "Loss: 1.32 Accuracy 12.16%\n",
      "Loss: 1.36 Accuracy 12.14%\n",
      "Loss: 1.35 Accuracy 12.14%\n",
      "Loss: 1.33 Accuracy 12.14%\n",
      "Loss: 1.32 Accuracy 12.14%\n",
      "Loss: 1.35 Accuracy 12.13%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.29 Accuracy 12.14%\n",
      "Loss: 1.33 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.11%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.30 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.34 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.31 Accuracy 12.13%\n",
      "Loss: 1.32 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.31 Accuracy 12.13%\n",
      "Loss: 1.31 Accuracy 12.13%\n",
      "Loss: 1.30 Accuracy 12.14%\n",
      "Loss: 1.31 Accuracy 12.14%\n",
      "Loss: 1.33 Accuracy 12.14%\n",
      "Loss: 1.34 Accuracy 12.13%\n",
      "Loss: 1.31 Accuracy 12.14%\n",
      "Loss: 1.34 Accuracy 12.13%\n",
      "Loss: 1.34 Accuracy 12.13%\n",
      "Loss: 1.36 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.13%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.35 Accuracy 12.12%\n",
      "Loss: 1.33 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.12%\n",
      "Loss: 1.32 Accuracy 12.11%\n",
      "Test Accuracy: 59.05%\n",
      "Epoch 9\n",
      "Loss: 0.14 Accuracy 6.25%\n",
      "Loss: 0.90 Accuracy 11.93%\n",
      "Loss: 1.17 Accuracy 11.90%\n",
      "Loss: 1.23 Accuracy 13.41%\n",
      "Loss: 1.26 Accuracy 13.87%\n",
      "Loss: 1.31 Accuracy 13.36%\n",
      "Loss: 1.30 Accuracy 13.52%\n",
      "Loss: 1.32 Accuracy 13.42%\n",
      "Loss: 1.32 Accuracy 13.27%\n",
      "Loss: 1.32 Accuracy 13.12%\n",
      "Loss: 1.31 Accuracy 13.24%\n",
      "Loss: 1.34 Accuracy 12.98%\n",
      "Loss: 1.31 Accuracy 13.09%\n",
      "Loss: 1.33 Accuracy 13.00%\n",
      "Loss: 1.33 Accuracy 12.94%\n",
      "Loss: 1.29 Accuracy 13.08%\n",
      "Loss: 1.30 Accuracy 13.12%\n",
      "Loss: 1.33 Accuracy 12.98%\n",
      "Loss: 1.36 Accuracy 12.78%\n",
      "Loss: 1.34 Accuracy 12.68%\n",
      "Loss: 1.34 Accuracy 12.53%\n",
      "Loss: 1.31 Accuracy 12.54%\n",
      "Loss: 1.35 Accuracy 12.37%\n",
      "Loss: 1.32 Accuracy 12.41%\n",
      "Loss: 1.30 Accuracy 12.49%\n",
      "Loss: 1.33 Accuracy 12.43%\n",
      "Loss: 1.32 Accuracy 12.42%\n",
      "Loss: 1.29 Accuracy 12.53%\n",
      "Loss: 1.28 Accuracy 12.62%\n",
      "Loss: 1.31 Accuracy 12.58%\n",
      "Loss: 1.32 Accuracy 12.57%\n",
      "Loss: 1.33 Accuracy 12.56%\n",
      "Loss: 1.33 Accuracy 12.52%\n",
      "Loss: 1.33 Accuracy 12.50%\n",
      "Loss: 1.31 Accuracy 12.52%\n",
      "Loss: 1.28 Accuracy 12.58%\n",
      "Loss: 1.32 Accuracy 12.56%\n",
      "Loss: 1.29 Accuracy 12.61%\n",
      "Loss: 1.31 Accuracy 12.61%\n",
      "Loss: 1.32 Accuracy 12.61%\n",
      "Loss: 1.33 Accuracy 12.59%\n",
      "Loss: 1.31 Accuracy 12.60%\n",
      "Loss: 1.30 Accuracy 12.62%\n",
      "Loss: 1.29 Accuracy 12.67%\n",
      "Loss: 1.30 Accuracy 12.69%\n",
      "Loss: 1.32 Accuracy 12.69%\n",
      "Loss: 1.33 Accuracy 12.67%\n",
      "Loss: 1.35 Accuracy 12.65%\n",
      "Loss: 1.31 Accuracy 12.71%\n",
      "Loss: 1.29 Accuracy 12.73%\n",
      "Loss: 1.31 Accuracy 12.74%\n",
      "Loss: 1.33 Accuracy 12.70%\n",
      "Loss: 1.34 Accuracy 12.64%\n",
      "Loss: 1.33 Accuracy 12.61%\n",
      "Loss: 1.30 Accuracy 12.64%\n",
      "Loss: 1.32 Accuracy 12.63%\n",
      "Loss: 1.34 Accuracy 12.57%\n",
      "Loss: 1.35 Accuracy 12.53%\n",
      "Loss: 1.30 Accuracy 12.57%\n",
      "Loss: 1.32 Accuracy 12.56%\n",
      "Loss: 1.33 Accuracy 12.55%\n",
      "Loss: 1.30 Accuracy 12.58%\n",
      "Loss: 1.31 Accuracy 12.56%\n",
      "Loss: 1.31 Accuracy 12.55%\n",
      "Loss: 1.32 Accuracy 12.55%\n",
      "Loss: 1.31 Accuracy 12.57%\n",
      "Loss: 1.35 Accuracy 12.51%\n",
      "Loss: 1.32 Accuracy 12.51%\n",
      "Loss: 1.29 Accuracy 12.56%\n",
      "Loss: 1.34 Accuracy 12.52%\n",
      "Loss: 1.33 Accuracy 12.52%\n",
      "Loss: 1.34 Accuracy 12.50%\n",
      "Loss: 1.32 Accuracy 12.51%\n",
      "Loss: 1.32 Accuracy 12.49%\n",
      "Loss: 1.34 Accuracy 12.47%\n",
      "Loss: 1.30 Accuracy 12.49%\n",
      "Loss: 1.31 Accuracy 12.49%\n",
      "Loss: 1.34 Accuracy 12.46%\n",
      "Loss: 1.29 Accuracy 12.49%\n",
      "Loss: 1.28 Accuracy 12.52%\n",
      "Loss: 1.32 Accuracy 12.50%\n",
      "Loss: 1.33 Accuracy 12.47%\n",
      "Loss: 1.28 Accuracy 12.52%\n",
      "Loss: 1.34 Accuracy 12.47%\n",
      "Loss: 1.32 Accuracy 12.47%\n",
      "Loss: 1.30 Accuracy 12.49%\n",
      "Loss: 1.32 Accuracy 12.47%\n",
      "Loss: 1.33 Accuracy 12.45%\n",
      "Loss: 1.35 Accuracy 12.43%\n",
      "Loss: 1.29 Accuracy 12.45%\n",
      "Loss: 1.33 Accuracy 12.43%\n",
      "Loss: 1.29 Accuracy 12.45%\n",
      "Loss: 1.31 Accuracy 12.46%\n",
      "Loss: 1.28 Accuracy 12.48%\n",
      "Loss: 1.30 Accuracy 12.49%\n",
      "Loss: 1.26 Accuracy 12.55%\n",
      "Loss: 1.31 Accuracy 12.53%\n",
      "Loss: 1.31 Accuracy 12.53%\n",
      "Loss: 1.32 Accuracy 12.52%\n",
      "Loss: 1.33 Accuracy 12.51%\n",
      "Loss: 1.34 Accuracy 12.49%\n",
      "Loss: 1.32 Accuracy 12.49%\n",
      "Loss: 1.34 Accuracy 12.47%\n",
      "Loss: 1.32 Accuracy 12.48%\n",
      "Loss: 1.33 Accuracy 12.47%\n",
      "Loss: 1.33 Accuracy 12.47%\n",
      "Loss: 1.31 Accuracy 12.48%\n",
      "Loss: 1.30 Accuracy 12.49%\n",
      "Loss: 1.33 Accuracy 12.47%\n",
      "Loss: 1.31 Accuracy 12.47%\n",
      "Loss: 1.32 Accuracy 12.47%\n",
      "Loss: 1.32 Accuracy 12.48%\n",
      "Loss: 1.31 Accuracy 12.49%\n",
      "Loss: 1.30 Accuracy 12.50%\n",
      "Loss: 1.30 Accuracy 12.51%\n",
      "Loss: 1.34 Accuracy 12.49%\n",
      "Loss: 1.35 Accuracy 12.47%\n",
      "Loss: 1.35 Accuracy 12.44%\n",
      "Loss: 1.32 Accuracy 12.45%\n",
      "Loss: 1.30 Accuracy 12.46%\n",
      "Loss: 1.32 Accuracy 12.45%\n",
      "Loss: 1.34 Accuracy 12.44%\n",
      "Loss: 1.34 Accuracy 12.43%\n",
      "Loss: 1.28 Accuracy 12.46%\n",
      "Loss: 1.34 Accuracy 12.44%\n",
      "Loss: 1.31 Accuracy 12.45%\n",
      "Loss: 1.30 Accuracy 12.46%\n",
      "Loss: 1.36 Accuracy 12.42%\n",
      "Loss: 1.33 Accuracy 12.42%\n",
      "Loss: 1.32 Accuracy 12.42%\n",
      "Loss: 1.27 Accuracy 12.46%\n",
      "Loss: 1.30 Accuracy 12.45%\n",
      "Loss: 1.32 Accuracy 12.44%\n",
      "Loss: 1.33 Accuracy 12.43%\n",
      "Loss: 1.34 Accuracy 12.42%\n",
      "Loss: 1.34 Accuracy 12.41%\n",
      "Loss: 1.34 Accuracy 12.41%\n",
      "Loss: 1.30 Accuracy 12.43%\n",
      "Loss: 1.35 Accuracy 12.40%\n",
      "Loss: 1.33 Accuracy 12.40%\n",
      "Loss: 1.33 Accuracy 12.39%\n",
      "Loss: 1.31 Accuracy 12.40%\n",
      "Loss: 1.34 Accuracy 12.38%\n",
      "Loss: 1.31 Accuracy 12.40%\n",
      "Loss: 1.30 Accuracy 12.40%\n",
      "Loss: 1.33 Accuracy 12.40%\n",
      "Loss: 1.32 Accuracy 12.40%\n",
      "Loss: 1.36 Accuracy 12.37%\n",
      "Loss: 1.32 Accuracy 12.38%\n",
      "Loss: 1.33 Accuracy 12.37%\n",
      "Loss: 1.31 Accuracy 12.38%\n",
      "Loss: 1.31 Accuracy 12.38%\n",
      "Loss: 1.37 Accuracy 12.34%\n",
      "Loss: 1.33 Accuracy 12.35%\n",
      "Loss: 1.33 Accuracy 12.34%\n",
      "Loss: 1.34 Accuracy 12.33%\n",
      "Loss: 1.36 Accuracy 12.31%\n",
      "Loss: 1.32 Accuracy 12.32%\n",
      "Loss: 1.33 Accuracy 12.31%\n",
      "Loss: 1.33 Accuracy 12.31%\n",
      "Loss: 1.28 Accuracy 12.33%\n",
      "Loss: 1.30 Accuracy 12.33%\n",
      "Loss: 1.32 Accuracy 12.33%\n",
      "Loss: 1.32 Accuracy 12.33%\n",
      "Loss: 1.34 Accuracy 12.32%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.35 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.31 Accuracy 12.29%\n",
      "Loss: 1.32 Accuracy 12.29%\n",
      "Loss: 1.33 Accuracy 12.29%\n",
      "Loss: 1.31 Accuracy 12.29%\n",
      "Loss: 1.33 Accuracy 12.29%\n",
      "Loss: 1.34 Accuracy 12.28%\n",
      "Loss: 1.32 Accuracy 12.29%\n",
      "Loss: 1.35 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.28%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.28 Accuracy 12.30%\n",
      "Loss: 1.30 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.33 Accuracy 12.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.33 Accuracy 12.29%\n",
      "Loss: 1.33 Accuracy 12.30%\n",
      "Loss: 1.31 Accuracy 12.31%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.33 Accuracy 12.31%\n",
      "Loss: 1.33 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.34 Accuracy 12.29%\n",
      "Loss: 1.35 Accuracy 12.29%\n",
      "Loss: 1.30 Accuracy 12.31%\n",
      "Loss: 1.30 Accuracy 12.31%\n",
      "Loss: 1.29 Accuracy 12.33%\n",
      "Loss: 1.32 Accuracy 12.32%\n",
      "Loss: 1.30 Accuracy 12.33%\n",
      "Loss: 1.31 Accuracy 12.33%\n",
      "Loss: 1.34 Accuracy 12.33%\n",
      "Loss: 1.34 Accuracy 12.32%\n",
      "Loss: 1.35 Accuracy 12.31%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.31 Accuracy 12.31%\n",
      "Loss: 1.34 Accuracy 12.30%\n",
      "Loss: 1.33 Accuracy 12.31%\n",
      "Loss: 1.29 Accuracy 12.32%\n",
      "Loss: 1.33 Accuracy 12.31%\n",
      "Loss: 1.35 Accuracy 12.30%\n",
      "Loss: 1.32 Accuracy 12.30%\n",
      "Loss: 1.29 Accuracy 12.32%\n",
      "Loss: 1.34 Accuracy 12.31%\n",
      "Loss: 1.33 Accuracy 12.30%\n",
      "Loss: 1.34 Accuracy 12.29%\n",
      "Loss: 1.38 Accuracy 12.27%\n",
      "Loss: 1.35 Accuracy 12.26%\n",
      "Loss: 1.33 Accuracy 12.26%\n",
      "Loss: 1.31 Accuracy 12.27%\n",
      "Loss: 1.34 Accuracy 12.26%\n",
      "Loss: 1.30 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.27%\n",
      "Loss: 1.32 Accuracy 12.27%\n",
      "Loss: 1.33 Accuracy 12.26%\n",
      "Loss: 1.36 Accuracy 12.25%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.34 Accuracy 12.24%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.29 Accuracy 12.26%\n",
      "Loss: 1.32 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.25%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.31 Accuracy 12.25%\n",
      "Loss: 1.29 Accuracy 12.26%\n",
      "Loss: 1.28 Accuracy 12.28%\n",
      "Loss: 1.29 Accuracy 12.28%\n",
      "Loss: 1.30 Accuracy 12.29%\n",
      "Loss: 1.31 Accuracy 12.28%\n",
      "Loss: 1.34 Accuracy 12.27%\n",
      "Loss: 1.36 Accuracy 12.26%\n",
      "Loss: 1.34 Accuracy 12.26%\n",
      "Loss: 1.36 Accuracy 12.25%\n",
      "Loss: 1.36 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.33 Accuracy 12.24%\n",
      "Loss: 1.31 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.24%\n",
      "Loss: 1.34 Accuracy 12.23%\n",
      "Loss: 1.32 Accuracy 12.24%\n",
      "Loss: 1.35 Accuracy 12.22%\n",
      "Loss: 1.33 Accuracy 12.23%\n",
      "Loss: 1.35 Accuracy 12.22%\n",
      "Loss: 1.32 Accuracy 12.22%\n",
      "Loss: 1.35 Accuracy 12.21%\n",
      "Loss: 1.34 Accuracy 12.21%\n",
      "Loss: 1.37 Accuracy 12.19%\n",
      "Loss: 1.34 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.34 Accuracy 12.18%\n",
      "Loss: 1.33 Accuracy 12.18%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.36 Accuracy 12.17%\n",
      "Loss: 1.36 Accuracy 12.16%\n",
      "Loss: 1.31 Accuracy 12.18%\n",
      "Loss: 1.31 Accuracy 12.18%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.18%\n",
      "Loss: 1.32 Accuracy 12.18%\n",
      "Loss: 1.29 Accuracy 12.19%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.33 Accuracy 12.18%\n",
      "Loss: 1.34 Accuracy 12.18%\n",
      "Loss: 1.31 Accuracy 12.18%\n",
      "Loss: 1.31 Accuracy 12.19%\n",
      "Loss: 1.32 Accuracy 12.19%\n",
      "Loss: 1.35 Accuracy 12.18%\n",
      "Loss: 1.37 Accuracy 12.17%\n",
      "Test Accuracy: 58.66%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from pytorch_ood.loss import OutlierExposureLoss\n",
    "\n",
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "criterion = OutlierExposureLoss(alpha=0.5)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    loss_ema = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.train()\n",
    "    for n, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_ema = loss_ema * 0.9 + loss.data.cpu().numpy() * 0.1\n",
    "\n",
    "        pred = logits.max(dim=1).indices\n",
    "        correct += pred.eq(labels).sum().data.cpu().numpy()\n",
    "        total += pred.shape[0]\n",
    "\n",
    "        if n % 10 == 0:\n",
    "            print(f\"Loss: {loss_ema.item():.2f} Accuracy {correct/total:.2%}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for n, batch in enumerate(test_loader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            logits = model(inputs)\n",
    "            pred = logits.max(dim=1).indices\n",
    "            correct += pred.eq(labels).sum().data.cpu().numpy()\n",
    "            total += pred.shape[0]\n",
    "\n",
    "        print(f\"Test Accuracy: {correct/total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirchheim/anaconda3/envs/myenv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/kirchheim/anaconda3/envs/myenv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/kirchheim/anaconda3/envs/myenv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: `pos_label` automatically set 1.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/kirchheim/anaconda3/envs/myenv/lib/python3.8/site-packages/torchmetrics/functional/classification/precision_recall_curve.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  thresholds = tensor(reversed(thresholds[sl]))\n"
     ]
    }
   ],
   "source": [
    "def test(model, dataset, dataset_name):\n",
    "    test_loader = DataLoader(dataset, batch_size=256, shuffle=True, collate_fn=collate_batch)\n",
    "    metrics = OODMetrics()\n",
    "    metrics_energy = OODMetrics()\n",
    "    softmax = MaxSoftmax(model)\n",
    "    energy = EnergyBased(model)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n, batch in enumerate(test_loader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            metrics.update(softmax(inputs), labels)\n",
    "            metrics_energy.update(energy(inputs), labels)\n",
    "\n",
    "    d1 = metrics.compute()\n",
    "    d1.update({\"Method\": \"Softmax\", \"Dataset\": dataset_name})\n",
    "    \n",
    "    d2 = metrics_energy.compute()\n",
    "    d2.update({\"Method\": \"Energy\", \"Dataset\": dataset_name})\n",
    "    return [d1, d2]\n",
    "\n",
    "res = []\n",
    "\n",
    "ood_dataset = Reuters52(\"data/\", train=False, download=True, transform=prep, target_transform=ToUnknown())\n",
    "res+= test(model, test_dataset + ood_dataset, dataset_name=\"Reuters52\")\n",
    "\n",
    "ood_dataset = Multi30k(\"data/\", train=False, download=True, transform=prep, target_transform=ToUnknown())\n",
    "res+= test(model, test_dataset + ood_dataset, dataset_name=\"Multi30k\")\n",
    "\n",
    "ood_dataset = WMT16Sentences(\"data/\", download=True, transform=prep, target_transform=ToUnknown())\n",
    "res+= test(model, test_dataset + ood_dataset, dataset_name=\"WMT16Sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  AUROC &  AUPR-IN &  AUPR-OUT &  ACC95TPR &  FPR95TPR \\\\\n",
      "Method  &        &          &           &           &           \\\\\n",
      "\\midrule\n",
      "Energy  &  93.93 &    78.20 &     97.02 &     84.93 &     18.94 \\\\\n",
      "Softmax &  93.22 &    77.65 &     96.42 &     82.06 &     23.11 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(res)\n",
    "print((df.groupby(\"Method\").mean() * 100).to_latex(float_format=\"%.2f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
